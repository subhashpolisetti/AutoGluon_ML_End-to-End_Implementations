{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "V28"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Introduction to AutoGluon\n",
        "\n",
        "AutoGluon is an open-source library designed to simplify the process of machine learning by automating the model selection and training process. It’s particularly useful for tabular data, and allows you to train high-quality models with minimal effort and code.\n",
        "\n",
        "**Key features of AutoGluon:**\n",
        "- **AutoML for Tabular Data**: AutoGluon automatically selects and trains a variety of models (like Random Forests, XGBoost, Neural Networks, etc.) to find the best-performing model for your dataset.\n",
        "- **Ensemble Methods**: AutoGluon combines different models through ensembling techniques to boost prediction accuracy.\n",
        "- **Easy-to-Use API**: With only a few lines of code, you can build powerful machine learning models.\n",
        "- **Hyperparameter Optimization**: AutoGluon automates the process of hyperparameter tuning, helping you find the best parameters for your models.\n",
        "- **Supports Multiple Task Types**: You can use AutoGluon for classification, regression, and other tasks with minimal configuration.\n",
        "\n",
        "AutoGluon is an excellent choice for users who want to quickly build predictive models without needing to fine-tune machine learning algorithms manually.\n"
      ],
      "metadata": {
        "id": "4bi9EErtPGNx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "FfSmBk33PD0V",
        "outputId": "04bac5a9-718c-4d31-f11f-df8b95fd07b2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting autogluon\n",
            "  Downloading autogluon-1.1.1-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting autogluon.core==1.1.1 (from autogluon.core[all]==1.1.1->autogluon)\n",
            "  Downloading autogluon.core-1.1.1-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting autogluon.features==1.1.1 (from autogluon)\n",
            "  Downloading autogluon.features-1.1.1-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting autogluon.tabular==1.1.1 (from autogluon.tabular[all]==1.1.1->autogluon)\n",
            "  Downloading autogluon.tabular-1.1.1-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting autogluon.multimodal==1.1.1 (from autogluon)\n",
            "  Downloading autogluon.multimodal-1.1.1-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting autogluon.timeseries==1.1.1 (from autogluon.timeseries[all]==1.1.1->autogluon)\n",
            "  Downloading autogluon.timeseries-1.1.1-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: numpy<1.29,>=1.21 in /usr/local/lib/python3.10/dist-packages (from autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon) (1.26.4)\n",
            "Collecting scipy<1.13,>=1.5.4 (from autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon)\n",
            "  Downloading scipy-1.12.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.4/60.4 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting scikit-learn<1.4.1,>=1.3.0 (from autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon)\n",
            "  Downloading scikit_learn-1.4.0-1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
            "Requirement already satisfied: networkx<4,>=3.0 in /usr/local/lib/python3.10/dist-packages (from autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon) (3.3)\n",
            "Requirement already satisfied: pandas<2.3.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon) (2.2.2)\n",
            "Requirement already satisfied: tqdm<5,>=4.38 in /usr/local/lib/python3.10/dist-packages (from autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon) (4.66.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon) (2.32.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon) (3.7.1)\n",
            "Collecting boto3<2,>=1.10 (from autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon)\n",
            "  Downloading boto3-1.35.34-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting autogluon.common==1.1.1 (from autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon)\n",
            "  Downloading autogluon.common-1.1.1-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting ray<2.11,>=2.10.0 (from ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon)\n",
            "  Downloading ray-2.10.0-cp310-cp310-manylinux2014_x86_64.whl.metadata (13 kB)\n",
            "Collecting hyperopt<0.2.8,>=0.2.7 (from autogluon.core[all]==1.1.1->autogluon)\n",
            "  Downloading hyperopt-0.2.7-py2.py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: Pillow<11,>=10.0.1 in /usr/local/lib/python3.10/dist-packages (from autogluon.multimodal==1.1.1->autogluon) (10.4.0)\n",
            "Collecting torch<2.4,>=2.2 (from autogluon.multimodal==1.1.1->autogluon)\n",
            "  Downloading torch-2.3.1-cp310-cp310-manylinux1_x86_64.whl.metadata (26 kB)\n",
            "Collecting lightning<2.4,>=2.2 (from autogluon.multimodal==1.1.1->autogluon)\n",
            "  Downloading lightning-2.3.3-py3-none-any.whl.metadata (35 kB)\n",
            "Collecting transformers<4.41.0,>=4.38.0 (from transformers[sentencepiece]<4.41.0,>=4.38.0->autogluon.multimodal==1.1.1->autogluon)\n",
            "  Downloading transformers-4.40.2-py3-none-any.whl.metadata (137 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.0/138.0 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting accelerate<0.22.0,>=0.21.0 (from autogluon.multimodal==1.1.1->autogluon)\n",
            "  Downloading accelerate-0.21.0-py3-none-any.whl.metadata (17 kB)\n",
            "Collecting jsonschema<4.22,>=4.18 (from autogluon.multimodal==1.1.1->autogluon)\n",
            "  Downloading jsonschema-4.21.1-py3-none-any.whl.metadata (7.8 kB)\n",
            "Collecting seqeval<1.3.0,>=1.2.2 (from autogluon.multimodal==1.1.1->autogluon)\n",
            "  Downloading seqeval-1.2.2.tar.gz (43 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting evaluate<0.5.0,>=0.4.0 (from autogluon.multimodal==1.1.1->autogluon)\n",
            "  Downloading evaluate-0.4.3-py3-none-any.whl.metadata (9.2 kB)\n",
            "Collecting timm<0.10.0,>=0.9.5 (from autogluon.multimodal==1.1.1->autogluon)\n",
            "  Downloading timm-0.9.16-py3-none-any.whl.metadata (38 kB)\n",
            "Collecting torchvision<0.19.0,>=0.16.0 (from autogluon.multimodal==1.1.1->autogluon)\n",
            "  Downloading torchvision-0.18.1-cp310-cp310-manylinux1_x86_64.whl.metadata (6.6 kB)\n",
            "Collecting scikit-image<0.21.0,>=0.19.1 (from autogluon.multimodal==1.1.1->autogluon)\n",
            "  Downloading scikit_image-0.20.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (16 kB)\n",
            "Requirement already satisfied: text-unidecode<1.4,>=1.3 in /usr/local/lib/python3.10/dist-packages (from autogluon.multimodal==1.1.1->autogluon) (1.3)\n",
            "Collecting torchmetrics<1.3.0,>=1.2.0 (from autogluon.multimodal==1.1.1->autogluon)\n",
            "  Downloading torchmetrics-1.2.1-py3-none-any.whl.metadata (20 kB)\n",
            "Collecting nptyping<2.5.0,>=1.4.4 (from autogluon.multimodal==1.1.1->autogluon)\n",
            "  Downloading nptyping-2.4.1-py3-none-any.whl.metadata (7.7 kB)\n",
            "Collecting omegaconf<2.3.0,>=2.1.1 (from autogluon.multimodal==1.1.1->autogluon)\n",
            "  Downloading omegaconf-2.2.3-py3-none-any.whl.metadata (3.9 kB)\n",
            "Collecting pytorch-metric-learning<2.4,>=1.3.0 (from autogluon.multimodal==1.1.1->autogluon)\n",
            "  Downloading pytorch_metric_learning-2.3.0-py3-none-any.whl.metadata (17 kB)\n",
            "Collecting nlpaug<1.2.0,>=1.1.10 (from autogluon.multimodal==1.1.1->autogluon)\n",
            "  Downloading nlpaug-1.1.11-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: nltk<4.0.0,>=3.4.5 in /usr/local/lib/python3.10/dist-packages (from autogluon.multimodal==1.1.1->autogluon) (3.8.1)\n",
            "Collecting openmim<0.4.0,>=0.3.7 (from autogluon.multimodal==1.1.1->autogluon)\n",
            "  Downloading openmim-0.3.9-py2.py3-none-any.whl.metadata (16 kB)\n",
            "Requirement already satisfied: defusedxml<0.7.2,>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from autogluon.multimodal==1.1.1->autogluon) (0.7.1)\n",
            "Requirement already satisfied: jinja2<3.2,>=3.0.3 in /usr/local/lib/python3.10/dist-packages (from autogluon.multimodal==1.1.1->autogluon) (3.1.4)\n",
            "Requirement already satisfied: tensorboard<3,>=2.9 in /usr/local/lib/python3.10/dist-packages (from autogluon.multimodal==1.1.1->autogluon) (2.15.2)\n",
            "Collecting pytesseract<0.3.11,>=0.3.9 (from autogluon.multimodal==1.1.1->autogluon)\n",
            "  Downloading pytesseract-0.3.10-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting nvidia-ml-py3==7.352.0 (from autogluon.multimodal==1.1.1->autogluon)\n",
            "  Downloading nvidia-ml-py3-7.352.0.tar.gz (19 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pdf2image<1.19,>=1.17.0 (from autogluon.multimodal==1.1.1->autogluon)\n",
            "  Downloading pdf2image-1.17.0-py3-none-any.whl.metadata (6.2 kB)\n",
            "Collecting xgboost<2.1,>=1.6 (from autogluon.tabular[all]==1.1.1->autogluon)\n",
            "  Downloading xgboost-2.0.3-py3-none-manylinux2014_x86_64.whl.metadata (2.0 kB)\n",
            "Requirement already satisfied: fastai<2.8,>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from autogluon.tabular[all]==1.1.1->autogluon) (2.7.17)\n",
            "Collecting lightgbm<4.4,>=3.3 (from autogluon.tabular[all]==1.1.1->autogluon)\n",
            "  Downloading lightgbm-4.3.0-py3-none-manylinux_2_28_x86_64.whl.metadata (19 kB)\n",
            "Collecting catboost<1.3,>=1.1 (from autogluon.tabular[all]==1.1.1->autogluon)\n",
            "  Downloading catboost-1.2.7-cp310-cp310-manylinux2014_x86_64.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: joblib<2,>=1.1 in /usr/local/lib/python3.10/dist-packages (from autogluon.timeseries==1.1.1->autogluon.timeseries[all]==1.1.1->autogluon) (1.4.2)\n",
            "Collecting pytorch-lightning<2.4,>=2.2 (from autogluon.timeseries==1.1.1->autogluon.timeseries[all]==1.1.1->autogluon)\n",
            "  Downloading pytorch_lightning-2.3.3-py3-none-any.whl.metadata (21 kB)\n",
            "Collecting gluonts==0.15.1 (from autogluon.timeseries==1.1.1->autogluon.timeseries[all]==1.1.1->autogluon)\n",
            "  Downloading gluonts-0.15.1-py3-none-any.whl.metadata (9.9 kB)\n",
            "Collecting statsforecast<1.5,>=1.4.0 (from autogluon.timeseries==1.1.1->autogluon.timeseries[all]==1.1.1->autogluon)\n",
            "  Downloading statsforecast-1.4.0-py3-none-any.whl.metadata (19 kB)\n",
            "Collecting mlforecast<0.10.1,>=0.10.0 (from autogluon.timeseries==1.1.1->autogluon.timeseries[all]==1.1.1->autogluon)\n",
            "  Downloading mlforecast-0.10.0-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting utilsforecast<0.0.11,>=0.0.10 (from autogluon.timeseries==1.1.1->autogluon.timeseries[all]==1.1.1->autogluon)\n",
            "  Downloading utilsforecast-0.0.10-py3-none-any.whl.metadata (7.0 kB)\n",
            "Collecting orjson~=3.9 (from autogluon.timeseries==1.1.1->autogluon.timeseries[all]==1.1.1->autogluon)\n",
            "  Downloading orjson-3.10.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (50 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.4/50.4 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting optimum<1.19,>=1.17 (from optimum[onnxruntime]<1.19,>=1.17; extra == \"all\"->autogluon.timeseries[all]==1.1.1->autogluon)\n",
            "  Downloading optimum-1.18.1-py3-none-any.whl.metadata (18 kB)\n",
            "Requirement already satisfied: psutil<6,>=5.7.3 in /usr/local/lib/python3.10/dist-packages (from autogluon.common==1.1.1->autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon) (5.9.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from autogluon.common==1.1.1->autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon) (71.0.4)\n",
            "Requirement already satisfied: pydantic<3,>=1.7 in /usr/local/lib/python3.10/dist-packages (from gluonts==0.15.1->autogluon.timeseries==1.1.1->autogluon.timeseries[all]==1.1.1->autogluon) (2.9.2)\n",
            "Requirement already satisfied: toolz~=0.10 in /usr/local/lib/python3.10/dist-packages (from gluonts==0.15.1->autogluon.timeseries==1.1.1->autogluon.timeseries[all]==1.1.1->autogluon) (0.12.1)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.10/dist-packages (from gluonts==0.15.1->autogluon.timeseries==1.1.1->autogluon.timeseries[all]==1.1.1->autogluon) (4.12.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate<0.22.0,>=0.21.0->autogluon.multimodal==1.1.1->autogluon) (24.1)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate<0.22.0,>=0.21.0->autogluon.multimodal==1.1.1->autogluon) (6.0.2)\n",
            "Collecting botocore<1.36.0,>=1.35.34 (from boto3<2,>=1.10->autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon)\n",
            "  Downloading botocore-1.35.34-py3-none-any.whl.metadata (5.6 kB)\n",
            "Collecting jmespath<2.0.0,>=0.7.1 (from boto3<2,>=1.10->autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon)\n",
            "  Downloading jmespath-1.0.1-py3-none-any.whl.metadata (7.6 kB)\n",
            "Collecting s3transfer<0.11.0,>=0.10.0 (from boto3<2,>=1.10->autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon)\n",
            "  Downloading s3transfer-0.10.2-py3-none-any.whl.metadata (1.7 kB)\n",
            "Collecting graphviz (from catboost<1.3,>=1.1->autogluon.tabular[all]==1.1.1->autogluon)\n",
            "  Downloading graphviz-0.20.3-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.10/dist-packages (from catboost<1.3,>=1.1->autogluon.tabular[all]==1.1.1->autogluon) (5.24.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from catboost<1.3,>=1.1->autogluon.tabular[all]==1.1.1->autogluon) (1.16.0)\n",
            "Collecting datasets>=2.0.0 (from evaluate<0.5.0,>=0.4.0->autogluon.multimodal==1.1.1->autogluon)\n",
            "  Downloading datasets-3.0.1-py3-none-any.whl.metadata (20 kB)\n",
            "Collecting dill (from evaluate<0.5.0,>=0.4.0->autogluon.multimodal==1.1.1->autogluon)\n",
            "  Downloading dill-0.3.9-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting xxhash (from evaluate<0.5.0,>=0.4.0->autogluon.multimodal==1.1.1->autogluon)\n",
            "  Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess (from evaluate<0.5.0,>=0.4.0->autogluon.multimodal==1.1.1->autogluon)\n",
            "  Downloading multiprocess-0.70.17-py310-none-any.whl.metadata (7.2 kB)\n",
            "Requirement already satisfied: fsspec>=2021.05.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]>=2021.05.0->evaluate<0.5.0,>=0.4.0->autogluon.multimodal==1.1.1->autogluon) (2024.9.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from evaluate<0.5.0,>=0.4.0->autogluon.multimodal==1.1.1->autogluon) (0.24.7)\n",
            "Requirement already satisfied: pip in /usr/local/lib/python3.10/dist-packages (from fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.1.1->autogluon) (24.1.2)\n",
            "Requirement already satisfied: fastdownload<2,>=0.0.5 in /usr/local/lib/python3.10/dist-packages (from fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.1.1->autogluon) (0.0.7)\n",
            "Requirement already satisfied: fastcore<1.8,>=1.5.29 in /usr/local/lib/python3.10/dist-packages (from fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.1.1->autogluon) (1.7.10)\n",
            "Requirement already satisfied: fastprogress>=0.2.4 in /usr/local/lib/python3.10/dist-packages (from fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.1.1->autogluon) (1.0.3)\n",
            "Requirement already satisfied: spacy<4 in /usr/local/lib/python3.10/dist-packages (from fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.1.1->autogluon) (3.7.5)\n",
            "Collecting future (from hyperopt<0.2.8,>=0.2.7->autogluon.core[all]==1.1.1->autogluon)\n",
            "  Downloading future-1.0.0-py3-none-any.whl.metadata (4.0 kB)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.10/dist-packages (from hyperopt<0.2.8,>=0.2.7->autogluon.core[all]==1.1.1->autogluon) (3.0.0)\n",
            "Collecting py4j (from hyperopt<0.2.8,>=0.2.7->autogluon.core[all]==1.1.1->autogluon)\n",
            "  Downloading py4j-0.10.9.7-py2.py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2<3.2,>=3.0.3->autogluon.multimodal==1.1.1->autogluon) (2.1.5)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema<4.22,>=4.18->autogluon.multimodal==1.1.1->autogluon) (24.2.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema<4.22,>=4.18->autogluon.multimodal==1.1.1->autogluon) (2023.12.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema<4.22,>=4.18->autogluon.multimodal==1.1.1->autogluon) (0.35.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema<4.22,>=4.18->autogluon.multimodal==1.1.1->autogluon) (0.20.0)\n",
            "Collecting lightning-utilities<2.0,>=0.10.0 (from lightning<2.4,>=2.2->autogluon.multimodal==1.1.1->autogluon)\n",
            "  Downloading lightning_utilities-0.11.7-py3-none-any.whl.metadata (5.2 kB)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.10/dist-packages (from mlforecast<0.10.1,>=0.10.0->autogluon.timeseries==1.1.1->autogluon.timeseries[all]==1.1.1->autogluon) (0.60.0)\n",
            "Collecting window-ops (from mlforecast<0.10.1,>=0.10.0->autogluon.timeseries==1.1.1->autogluon.timeseries[all]==1.1.1->autogluon)\n",
            "  Downloading window_ops-0.0.15-py3-none-any.whl.metadata (6.8 kB)\n",
            "Requirement already satisfied: gdown>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from nlpaug<1.2.0,>=1.1.10->autogluon.multimodal==1.1.1->autogluon) (5.2.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.4.5->autogluon.multimodal==1.1.1->autogluon) (8.1.7)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.4.5->autogluon.multimodal==1.1.1->autogluon) (2024.9.11)\n",
            "Collecting antlr4-python3-runtime==4.9.* (from omegaconf<2.3.0,>=2.1.1->autogluon.multimodal==1.1.1->autogluon)\n",
            "  Downloading antlr4-python3-runtime-4.9.3.tar.gz (117 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.0/117.0 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting colorama (from openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.1.1->autogluon)\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)\n",
            "Collecting model-index (from openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.1.1->autogluon)\n",
            "  Downloading model_index-0.1.11-py3-none-any.whl.metadata (3.9 kB)\n",
            "Collecting opendatalab (from openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.1.1->autogluon)\n",
            "  Downloading opendatalab-0.0.10-py3-none-any.whl.metadata (6.4 kB)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.1.1->autogluon) (13.9.1)\n",
            "Collecting tabulate (from openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.1.1->autogluon)\n",
            "  Downloading tabulate-0.9.0-py3-none-any.whl.metadata (34 kB)\n",
            "Collecting coloredlogs (from optimum<1.19,>=1.17->optimum[onnxruntime]<1.19,>=1.17; extra == \"all\"->autogluon.timeseries[all]==1.1.1->autogluon)\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from optimum<1.19,>=1.17->optimum[onnxruntime]<1.19,>=1.17; extra == \"all\"->autogluon.timeseries[all]==1.1.1->autogluon) (1.13.3)\n",
            "Collecting transformers<4.41.0,>=4.38.0 (from transformers[sentencepiece]<4.41.0,>=4.38.0->autogluon.multimodal==1.1.1->autogluon)\n",
            "  Downloading transformers-4.39.3-py3-none-any.whl.metadata (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting onnx (from optimum[onnxruntime]<1.19,>=1.17; extra == \"all\"->autogluon.timeseries[all]==1.1.1->autogluon)\n",
            "  Downloading onnx-1.17.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (16 kB)\n",
            "Collecting onnxruntime>=1.11.0 (from optimum[onnxruntime]<1.19,>=1.17; extra == \"all\"->autogluon.timeseries[all]==1.1.1->autogluon)\n",
            "  Downloading onnxruntime-1.19.2-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.5 kB)\n",
            "Requirement already satisfied: protobuf>=3.20.1 in /usr/local/lib/python3.10/dist-packages (from optimum[onnxruntime]<1.19,>=1.17; extra == \"all\"->autogluon.timeseries[all]==1.1.1->autogluon) (3.20.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas<2.3.0,>=2.0.0->autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<2.3.0,>=2.0.0->autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas<2.3.0,>=2.0.0->autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon) (2024.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from ray<2.11,>=2.10.0->ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon) (3.16.1)\n",
            "Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from ray<2.11,>=2.10.0->ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon) (1.1.0)\n",
            "Collecting aiosignal (from ray<2.11,>=2.10.0->ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon)\n",
            "  Downloading aiosignal-1.3.1-py3-none-any.whl.metadata (4.0 kB)\n",
            "Collecting frozenlist (from ray<2.11,>=2.10.0->ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon)\n",
            "  Downloading frozenlist-1.4.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting tensorboardX>=1.9 (from ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon)\n",
            "  Downloading tensorboardX-2.6.2.2-py2.py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: pyarrow>=6.0.1 in /usr/local/lib/python3.10/dist-packages (from ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon) (17.0.0)\n",
            "Collecting aiohttp>=3.7 (from ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon)\n",
            "  Downloading aiohttp-3.10.9-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.6 kB)\n",
            "Collecting aiohttp-cors (from ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon)\n",
            "  Downloading aiohttp_cors-0.7.0-py3-none-any.whl.metadata (20 kB)\n",
            "Collecting colorful (from ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon)\n",
            "  Downloading colorful-0.5.6-py2.py3-none-any.whl.metadata (16 kB)\n",
            "Collecting py-spy>=0.2.0 (from ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon)\n",
            "  Downloading py_spy-0.3.14-py2.py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.whl.metadata (16 kB)\n",
            "Collecting opencensus (from ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon)\n",
            "  Downloading opencensus-0.11.4-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: prometheus-client>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon) (0.21.0)\n",
            "Requirement already satisfied: smart-open in /usr/local/lib/python3.10/dist-packages (from ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon) (7.0.4)\n",
            "Collecting virtualenv!=20.21.1,>=20.0.24 (from ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon)\n",
            "  Downloading virtualenv-20.26.6-py3-none-any.whl.metadata (4.5 kB)\n",
            "Requirement already satisfied: grpcio>=1.42.0 in /usr/local/lib/python3.10/dist-packages (from ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon) (1.66.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon) (2024.8.30)\n",
            "Requirement already satisfied: imageio>=2.4.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image<0.21.0,>=0.19.1->autogluon.multimodal==1.1.1->autogluon) (2.35.1)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.10/dist-packages (from scikit-image<0.21.0,>=0.19.1->autogluon.multimodal==1.1.1->autogluon) (2024.9.20)\n",
            "Collecting PyWavelets>=1.1.1 (from scikit-image<0.21.0,>=0.19.1->autogluon.multimodal==1.1.1->autogluon)\n",
            "  Downloading pywavelets-1.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.0 kB)\n",
            "Requirement already satisfied: lazy_loader>=0.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image<0.21.0,>=0.19.1->autogluon.multimodal==1.1.1->autogluon) (0.4)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn<1.4.1,>=1.3.0->autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon) (3.5.0)\n",
            "Collecting statsmodels>=0.13.2 (from statsforecast<1.5,>=1.4.0->autogluon.timeseries==1.1.1->autogluon.timeseries[all]==1.1.1->autogluon)\n",
            "  Downloading statsmodels-0.14.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard<3,>=2.9->autogluon.multimodal==1.1.1->autogluon) (1.4.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<3,>=2.9->autogluon.multimodal==1.1.1->autogluon) (2.27.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<3,>=2.9->autogluon.multimodal==1.1.1->autogluon) (1.2.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<3,>=2.9->autogluon.multimodal==1.1.1->autogluon) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<3,>=2.9->autogluon.multimodal==1.1.1->autogluon) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<3,>=2.9->autogluon.multimodal==1.1.1->autogluon) (3.0.4)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (from timm<0.10.0,>=0.9.5->autogluon.multimodal==1.1.1->autogluon) (0.4.5)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch<2.4,>=2.2->autogluon.multimodal==1.1.1->autogluon)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch<2.4,>=2.2->autogluon.multimodal==1.1.1->autogluon)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch<2.4,>=2.2->autogluon.multimodal==1.1.1->autogluon)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch<2.4,>=2.2->autogluon.multimodal==1.1.1->autogluon)\n",
            "  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch<2.4,>=2.2->autogluon.multimodal==1.1.1->autogluon)\n",
            "  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch<2.4,>=2.2->autogluon.multimodal==1.1.1->autogluon)\n",
            "  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch<2.4,>=2.2->autogluon.multimodal==1.1.1->autogluon)\n",
            "  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch<2.4,>=2.2->autogluon.multimodal==1.1.1->autogluon)\n",
            "  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch<2.4,>=2.2->autogluon.multimodal==1.1.1->autogluon)\n",
            "  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch<2.4,>=2.2->autogluon.multimodal==1.1.1->autogluon)\n",
            "  Downloading nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch<2.4,>=2.2->autogluon.multimodal==1.1.1->autogluon)\n",
            "  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting triton==2.3.1 (from torch<2.4,>=2.2->autogluon.multimodal==1.1.1->autogluon)\n",
            "  Downloading triton-2.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.4 kB)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch<2.4,>=2.2->autogluon.multimodal==1.1.1->autogluon)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.6.77-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting tokenizers<0.19,>=0.14 (from transformers<4.41.0,>=4.38.0->transformers[sentencepiece]<4.41.0,>=4.38.0->autogluon.multimodal==1.1.1->autogluon)\n",
            "  Downloading tokenizers-0.15.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: sentencepiece!=0.1.92,>=0.1.91 in /usr/local/lib/python3.10/dist-packages (from transformers[sentencepiece]<4.41.0,>=4.38.0->autogluon.multimodal==1.1.1->autogluon) (0.2.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon) (1.3.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon) (4.54.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon) (1.4.7)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon) (3.1.4)\n",
            "Collecting aiohappyeyeballs>=2.3.0 (from aiohttp>=3.7->ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon)\n",
            "  Downloading aiohappyeyeballs-2.4.3-py3-none-any.whl.metadata (6.1 kB)\n",
            "Collecting multidict<7.0,>=4.5 (from aiohttp>=3.7->ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon)\n",
            "  Downloading multidict-6.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.0 kB)\n",
            "Collecting yarl<2.0,>=1.12.0 (from aiohttp>=3.7->ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon)\n",
            "  Downloading yarl-1.13.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (50 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.8/50.8 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting async-timeout<5.0,>=4.0 (from aiohttp>=3.7->ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon)\n",
            "  Downloading async_timeout-4.0.3-py3-none-any.whl.metadata (4.2 kB)\n",
            "Collecting dill (from evaluate<0.5.0,>=0.4.0->autogluon.multimodal==1.1.1->autogluon)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting fsspec>=2021.05.0 (from fsspec[http]>=2021.05.0->evaluate<0.5.0,>=0.4.0->autogluon.multimodal==1.1.1->autogluon)\n",
            "  Downloading fsspec-2024.6.1-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from gdown>=4.0.0->nlpaug<1.2.0,>=1.1.10->autogluon.multimodal==1.1.1->autogluon) (4.12.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<3,>=2.9->autogluon.multimodal==1.1.1->autogluon) (5.5.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<3,>=2.9->autogluon.multimodal==1.1.1->autogluon) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<3,>=2.9->autogluon.multimodal==1.1.1->autogluon) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<3,>=2.9->autogluon.multimodal==1.1.1->autogluon) (2.0.0)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba->mlforecast<0.10.1,>=0.10.0->autogluon.timeseries==1.1.1->autogluon.timeseries[all]==1.1.1->autogluon) (0.43.0)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.11.0->optimum[onnxruntime]<1.19,>=1.17; extra == \"all\"->autogluon.timeseries[all]==1.1.1->autogluon) (24.3.25)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.7->gluonts==0.15.1->autogluon.timeseries==1.1.1->autogluon.timeseries[all]==1.1.1->autogluon) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.7->gluonts==0.15.1->autogluon.timeseries==1.1.1->autogluon.timeseries[all]==1.1.1->autogluon) (2.23.4)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.1.1->autogluon) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.1.1->autogluon) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.1.1->autogluon) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.1.1->autogluon) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.1.1->autogluon) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.1.1->autogluon) (8.2.5)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.1.1->autogluon) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.1.1->autogluon) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.1.1->autogluon) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.1.1->autogluon) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.1.1->autogluon) (0.12.5)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.1.1->autogluon) (3.4.1)\n",
            "Collecting patsy>=0.5.6 (from statsmodels>=0.13.2->statsforecast<1.5,>=1.4.0->autogluon.timeseries==1.1.1->autogluon.timeseries[all]==1.1.1->autogluon)\n",
            "  Downloading patsy-0.5.6-py2.py3-none-any.whl.metadata (3.5 kB)\n",
            "Collecting distlib<1,>=0.3.7 (from virtualenv!=20.21.1,>=20.0.24->ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon)\n",
            "  Downloading distlib-0.3.8-py2.py3-none-any.whl.metadata (5.1 kB)\n",
            "Requirement already satisfied: platformdirs<5,>=3.9.1 in /usr/local/lib/python3.10/dist-packages (from virtualenv!=20.21.1,>=20.0.24->ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon) (4.3.6)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->optimum<1.19,>=1.17->optimum[onnxruntime]<1.19,>=1.17; extra == \"all\"->autogluon.timeseries[all]==1.1.1->autogluon)\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
            "Collecting ordered-set (from model-index->openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.1.1->autogluon)\n",
            "  Downloading ordered_set-4.1.0-py3-none-any.whl.metadata (5.3 kB)\n",
            "INFO: pip is looking at multiple versions of multiprocess to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting multiprocess (from evaluate<0.5.0,>=0.4.0->autogluon.multimodal==1.1.1->autogluon)\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\n",
            "Collecting opencensus-context>=0.1.3 (from opencensus->ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon)\n",
            "  Downloading opencensus_context-0.1.3-py2.py3-none-any.whl.metadata (3.3 kB)\n",
            "Requirement already satisfied: google-api-core<3.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from opencensus->ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon) (1.34.1)\n",
            "Collecting pycryptodome (from opendatalab->openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.1.1->autogluon)\n",
            "  Downloading pycryptodome-3.21.0-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.4 kB)\n",
            "Collecting openxlab (from opendatalab->openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.1.1->autogluon)\n",
            "  Downloading openxlab-0.1.1-py3-none-any.whl.metadata (3.8 kB)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from plotly->catboost<1.3,>=1.1->autogluon.tabular[all]==1.1.1->autogluon) (9.0.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.1.1->autogluon) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.1.1->autogluon) (2.18.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from smart-open->ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon) (1.14.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->optimum<1.19,>=1.17->optimum[onnxruntime]<1.19,>=1.17; extra == \"all\"->autogluon.timeseries[all]==1.1.1->autogluon) (1.3.0)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.56.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core<3.0.0,>=1.0.0->opencensus->ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon) (1.65.0)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.10/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.1.1->autogluon) (1.2.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.1.1->autogluon) (0.1.2)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<3,>=2.9->autogluon.multimodal==1.1.1->autogluon) (0.6.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<3,>=2.9->autogluon.multimodal==1.1.1->autogluon) (3.2.2)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.1.1->autogluon) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.1.1->autogluon) (0.1.5)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.1.1->autogluon) (1.5.4)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.1.1->autogluon) (0.19.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->gdown>=4.0.0->nlpaug<1.2.0,>=1.1.10->autogluon.multimodal==1.1.1->autogluon) (2.6)\n",
            "Collecting filelock (from ray<2.11,>=2.10.0->ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon)\n",
            "  Downloading filelock-3.14.0-py3-none-any.whl.metadata (2.8 kB)\n",
            "Collecting oss2~=2.17.0 (from openxlab->opendatalab->openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.1.1->autogluon)\n",
            "  Downloading oss2-2.17.0.tar.gz (259 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m259.5/259.5 kB\u001b[0m \u001b[31m19.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pytz>=2020.1 (from pandas<2.3.0,>=2.0.0->autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon)\n",
            "  Downloading pytz-2023.4-py2.py3-none-any.whl.metadata (22 kB)\n",
            "INFO: pip is looking at multiple versions of openxlab to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting openxlab (from opendatalab->openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.1.1->autogluon)\n",
            "  Downloading openxlab-0.1.0-py3-none-any.whl.metadata (3.8 kB)\n",
            "  Downloading openxlab-0.0.38-py3-none-any.whl.metadata (3.8 kB)\n",
            "  Downloading openxlab-0.0.37-py3-none-any.whl.metadata (3.8 kB)\n",
            "  Downloading openxlab-0.0.36-py3-none-any.whl.metadata (3.8 kB)\n",
            "  Downloading openxlab-0.0.35-py3-none-any.whl.metadata (3.8 kB)\n",
            "  Downloading openxlab-0.0.34-py3-none-any.whl.metadata (3.8 kB)\n",
            "  Downloading openxlab-0.0.33-py3-none-any.whl.metadata (3.8 kB)\n",
            "INFO: pip is still looking at multiple versions of openxlab to determine which version is compatible with other requirements. This could take a while.\n",
            "  Downloading openxlab-0.0.32-py3-none-any.whl.metadata (3.8 kB)\n",
            "  Downloading openxlab-0.0.31-py3-none-any.whl.metadata (3.8 kB)\n",
            "  Downloading openxlab-0.0.30-py3-none-any.whl.metadata (3.8 kB)\n",
            "  Downloading openxlab-0.0.29-py3-none-any.whl.metadata (3.8 kB)\n",
            "  Downloading openxlab-0.0.28-py3-none-any.whl.metadata (3.7 kB)\n",
            "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
            "  Downloading openxlab-0.0.27-py3-none-any.whl.metadata (3.7 kB)\n",
            "  Downloading openxlab-0.0.26-py3-none-any.whl.metadata (3.7 kB)\n",
            "  Downloading openxlab-0.0.25-py3-none-any.whl.metadata (3.7 kB)\n",
            "  Downloading openxlab-0.0.24-py3-none-any.whl.metadata (3.7 kB)\n",
            "  Downloading openxlab-0.0.23-py3-none-any.whl.metadata (3.7 kB)\n",
            "  Downloading openxlab-0.0.22-py3-none-any.whl.metadata (3.7 kB)\n",
            "  Downloading openxlab-0.0.21-py3-none-any.whl.metadata (3.7 kB)\n",
            "  Downloading openxlab-0.0.20-py3-none-any.whl.metadata (3.7 kB)\n",
            "  Downloading openxlab-0.0.19-py3-none-any.whl.metadata (3.7 kB)\n",
            "  Downloading openxlab-0.0.18-py3-none-any.whl.metadata (3.7 kB)\n",
            "  Downloading openxlab-0.0.17-py3-none-any.whl.metadata (3.7 kB)\n",
            "  Downloading openxlab-0.0.16-py3-none-any.whl.metadata (3.8 kB)\n",
            "  Downloading openxlab-0.0.15-py3-none-any.whl.metadata (3.8 kB)\n",
            "  Downloading openxlab-0.0.14-py3-none-any.whl.metadata (3.8 kB)\n",
            "  Downloading openxlab-0.0.13-py3-none-any.whl.metadata (4.5 kB)\n",
            "  Downloading openxlab-0.0.12-py3-none-any.whl.metadata (4.5 kB)\n",
            "  Downloading openxlab-0.0.11-py3-none-any.whl.metadata (4.3 kB)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown>=4.0.0->nlpaug<1.2.0,>=1.1.10->autogluon.multimodal==1.1.1->autogluon) (1.7.1)\n",
            "Requirement already satisfied: marisa-trie>=0.7.7 in /usr/local/lib/python3.10/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.1.1->autogluon) (1.2.0)\n",
            "Downloading autogluon-1.1.1-py3-none-any.whl (9.7 kB)\n",
            "Downloading autogluon.core-1.1.1-py3-none-any.whl (234 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m234.8/234.8 kB\u001b[0m \u001b[31m16.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading autogluon.features-1.1.1-py3-none-any.whl (63 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.4/63.4 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading autogluon.multimodal-1.1.1-py3-none-any.whl (427 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m428.0/428.0 kB\u001b[0m \u001b[31m29.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading autogluon.tabular-1.1.1-py3-none-any.whl (312 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m312.1/312.1 kB\u001b[0m \u001b[31m20.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading autogluon.timeseries-1.1.1-py3-none-any.whl (148 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m148.2/148.2 kB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading autogluon.common-1.1.1-py3-none-any.whl (64 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.6/64.6 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gluonts-0.15.1-py3-none-any.whl (1.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m49.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading accelerate-0.21.0-py3-none-any.whl (244 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m244.2/244.2 kB\u001b[0m \u001b[31m18.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading boto3-1.35.34-py3-none-any.whl (139 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.1/139.1 kB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading catboost-1.2.7-cp310-cp310-manylinux2014_x86_64.whl (98.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.7/98.7 MB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading evaluate-0.4.3-py3-none-any.whl (84 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.0/84.0 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading hyperopt-0.2.7-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m60.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jsonschema-4.21.1-py3-none-any.whl (85 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.5/85.5 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lightgbm-4.3.0-py3-none-manylinux_2_28_x86_64.whl (3.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m85.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lightning-2.3.3-py3-none-any.whl (808 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m808.5/808.5 kB\u001b[0m \u001b[31m39.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mlforecast-0.10.0-py3-none-any.whl (47 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.6/47.6 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nlpaug-1.1.11-py3-none-any.whl (410 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.5/410.5 kB\u001b[0m \u001b[31m27.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nptyping-2.4.1-py3-none-any.whl (36 kB)\n",
            "Downloading omegaconf-2.2.3-py3-none-any.whl (79 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.3/79.3 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading openmim-0.3.9-py2.py3-none-any.whl (52 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.7/52.7 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading optimum-1.18.1-py3-none-any.whl (410 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.0/410.0 kB\u001b[0m \u001b[31m25.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading orjson-3.10.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (141 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.9/141.9 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pdf2image-1.17.0-py3-none-any.whl (11 kB)\n",
            "Downloading pytesseract-0.3.10-py3-none-any.whl (14 kB)\n",
            "Downloading pytorch_lightning-2.3.3-py3-none-any.whl (812 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m812.3/812.3 kB\u001b[0m \u001b[31m39.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pytorch_metric_learning-2.3.0-py3-none-any.whl (115 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ray-2.10.0-cp310-cp310-manylinux2014_x86_64.whl (65.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.1/65.1 MB\u001b[0m \u001b[31m18.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading scikit_image-0.20.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.2/13.2 MB\u001b[0m \u001b[31m105.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading scikit_learn-1.4.0-1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.1/12.1 MB\u001b[0m \u001b[31m105.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading scipy-1.12.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (38.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m38.4/38.4 MB\u001b[0m \u001b[31m36.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading statsforecast-1.4.0-py3-none-any.whl (91 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.0/92.0 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading timm-0.9.16-py3-none-any.whl (2.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m75.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torch-2.3.1-cp310-cp310-manylinux1_x86_64.whl (779.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m779.1/779.1 MB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m99.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m894.4 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m39.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m520.5 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m21.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m176.2/176.2 MB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading triton-2.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (168.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.1/168.1 MB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torchmetrics-1.2.1-py3-none-any.whl (806 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m806.1/806.1 kB\u001b[0m \u001b[31m39.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torchvision-0.18.1-cp310-cp310-manylinux1_x86_64.whl (7.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m96.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading transformers-4.39.3-py3-none-any.whl (8.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.8/8.8 MB\u001b[0m \u001b[31m100.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading utilsforecast-0.0.10-py3-none-any.whl (30 kB)\n",
            "Downloading xgboost-2.0.3-py3-none-manylinux2014_x86_64.whl (297.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m297.1/297.1 MB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading aiohttp-3.10.9-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m54.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
            "Downloading botocore-1.35.34-py3-none-any.whl (12.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.6/12.6 MB\u001b[0m \u001b[31m104.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading datasets-3.0.1-py3-none-any.whl (471 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m471.6/471.6 kB\u001b[0m \u001b[31m31.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading frozenlist-1.4.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (239 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m239.5/239.5 kB\u001b[0m \u001b[31m19.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fsspec-2024.6.1-py3-none-any.whl (177 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.6/177.6 kB\u001b[0m \u001b[31m14.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
            "Downloading lightning_utilities-0.11.7-py3-none-any.whl (26 kB)\n",
            "Downloading onnxruntime-1.19.2-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (13.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.2/13.2 MB\u001b[0m \u001b[31m104.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading py_spy-0.3.14-py2.py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.whl (3.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m80.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pywavelets-1.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m91.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading s3transfer-0.10.2-py3-none-any.whl (82 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.7/82.7 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading statsmodels-0.14.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (10.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.8/10.8 MB\u001b[0m \u001b[31m108.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorboardX-2.6.2.2-py2.py3-none-any.whl (101 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.7/101.7 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tokenizers-0.15.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m91.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading virtualenv-20.26.6-py3-none-any.whl (6.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.0/6.0 MB\u001b[0m \u001b[31m108.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading aiohttp_cors-0.7.0-py3-none-any.whl (27 kB)\n",
            "Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading colorful-0.5.6-py2.py3-none-any.whl (201 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m201.4/201.4 kB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading future-1.0.0-py3-none-any.whl (491 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m491.3/491.3 kB\u001b[0m \u001b[31m31.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading graphviz-0.20.3-py3-none-any.whl (47 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.1/47.1 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading model_index-0.1.11-py3-none-any.whl (34 kB)\n",
            "Downloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading onnx-1.17.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.0/16.0 MB\u001b[0m \u001b[31m93.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opencensus-0.11.4-py2.py3-none-any.whl (128 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.2/128.2 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opendatalab-0.0.10-py3-none-any.whl (29 kB)\n",
            "Downloading py4j-0.10.9.7-py2.py3-none-any.whl (200 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m200.5/200.5 kB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tabulate-0.9.0-py3-none-any.whl (35 kB)\n",
            "Downloading window_ops-0.0.15-py3-none-any.whl (15 kB)\n",
            "Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading aiohappyeyeballs-2.4.3-py3-none-any.whl (14 kB)\n",
            "Downloading async_timeout-4.0.3-py3-none-any.whl (5.7 kB)\n",
            "Downloading distlib-0.3.8-py2.py3-none-any.whl (468 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m468.9/468.9 kB\u001b[0m \u001b[31m30.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multidict-6.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (124 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.6/124.6 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opencensus_context-0.1.3-py2.py3-none-any.whl (5.1 kB)\n",
            "Downloading patsy-0.5.6-py2.py3-none-any.whl (233 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m233.9/233.9 kB\u001b[0m \u001b[31m18.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading yarl-1.13.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (447 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m447.9/447.9 kB\u001b[0m \u001b[31m33.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.6.77-py3-none-manylinux2014_x86_64.whl (19.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.7/19.7 MB\u001b[0m \u001b[31m90.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading openxlab-0.0.11-py3-none-any.whl (55 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.3/55.3 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ordered_set-4.1.0-py3-none-any.whl (7.6 kB)\n",
            "Downloading pycryptodome-3.21.0-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m73.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: nvidia-ml-py3, antlr4-python3-runtime, seqeval\n",
            "  Building wheel for nvidia-ml-py3 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for nvidia-ml-py3: filename=nvidia_ml_py3-7.352.0-py3-none-any.whl size=19171 sha256=2e7564282578e0268fffa7f2c22719e4d42c38c87cb9d83a705ba0fe93b4765b\n",
            "  Stored in directory: /root/.cache/pip/wheels/5c/d8/c0/46899f8be7a75a2ffd197a23c8797700ea858b9b34819fbf9e\n",
            "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.9.3-py3-none-any.whl size=144554 sha256=8d3182f007c195a140a0dfd90f8502ce952bcc5531a3605ac1dbc036266e38ad\n",
            "  Stored in directory: /root/.cache/pip/wheels/12/93/dd/1f6a127edc45659556564c5730f6d4e300888f4bca2d4c5a88\n",
            "  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16161 sha256=d81dcdd0aee8b4d4a0866db9233ded02eefd03274328857a412d36cf90706d0a\n",
            "  Stored in directory: /root/.cache/pip/wheels/1a/67/4a/ad4082dd7dfc30f2abfe4d80a2ed5926a506eb8a972b4767fa\n",
            "Successfully built nvidia-ml-py3 antlr4-python3-runtime seqeval\n",
            "Installing collected packages: py4j, py-spy, opencensus-context, nvidia-ml-py3, distlib, colorful, antlr4-python3-runtime, xxhash, virtualenv, triton, tensorboardX, tabulate, scipy, PyWavelets, pytesseract, pycryptodome, pdf2image, patsy, orjson, ordered-set, openxlab, onnx, omegaconf, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nptyping, multidict, lightning-utilities, jmespath, humanfriendly, graphviz, future, fsspec, frozenlist, dill, colorama, async-timeout, aiohappyeyeballs, yarl, xgboost, window-ops, scikit-learn, scikit-image, nvidia-cusparse-cu12, nvidia-cudnn-cu12, multiprocess, model-index, lightgbm, hyperopt, coloredlogs, botocore, aiosignal, utilsforecast, tokenizers, statsmodels, seqeval, s3transfer, opendatalab, onnxruntime, nvidia-cusolver-cu12, jsonschema, gluonts, catboost, aiohttp, transformers, torch, statsforecast, ray, openmim, opencensus, nlpaug, mlforecast, boto3, aiohttp-cors, torchvision, torchmetrics, pytorch-metric-learning, datasets, autogluon.common, accelerate, timm, pytorch-lightning, optimum, evaluate, autogluon.features, autogluon.core, lightning, autogluon.tabular, autogluon.multimodal, autogluon.timeseries, autogluon\n",
            "  Attempting uninstall: scipy\n",
            "    Found existing installation: scipy 1.13.1\n",
            "    Uninstalling scipy-1.13.1:\n",
            "      Successfully uninstalled scipy-1.13.1\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2024.9.0\n",
            "    Uninstalling fsspec-2024.9.0:\n",
            "      Successfully uninstalled fsspec-2024.9.0\n",
            "  Attempting uninstall: scikit-learn\n",
            "    Found existing installation: scikit-learn 1.5.2\n",
            "    Uninstalling scikit-learn-1.5.2:\n",
            "      Successfully uninstalled scikit-learn-1.5.2\n",
            "  Attempting uninstall: scikit-image\n",
            "    Found existing installation: scikit-image 0.24.0\n",
            "    Uninstalling scikit-image-0.24.0:\n",
            "      Successfully uninstalled scikit-image-0.24.0\n",
            "  Attempting uninstall: tokenizers\n",
            "    Found existing installation: tokenizers 0.19.1\n",
            "    Uninstalling tokenizers-0.19.1:\n",
            "      Successfully uninstalled tokenizers-0.19.1\n",
            "  Attempting uninstall: jsonschema\n",
            "    Found existing installation: jsonschema 4.23.0\n",
            "    Uninstalling jsonschema-4.23.0:\n",
            "      Successfully uninstalled jsonschema-4.23.0\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.44.2\n",
            "    Uninstalling transformers-4.44.2:\n",
            "      Successfully uninstalled transformers-4.44.2\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.4.0+cpu\n",
            "    Uninstalling torch-2.4.0+cpu:\n",
            "      Successfully uninstalled torch-2.4.0+cpu\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.19.0+cpu\n",
            "    Uninstalling torchvision-0.19.0+cpu:\n",
            "      Successfully uninstalled torchvision-0.19.0+cpu\n",
            "  Attempting uninstall: accelerate\n",
            "    Found existing installation: accelerate 0.34.2\n",
            "    Uninstalling accelerate-0.34.2:\n",
            "      Successfully uninstalled accelerate-0.34.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchaudio 2.4.0+cpu requires torch==2.4.0, but you have torch 2.3.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed PyWavelets-1.7.0 accelerate-0.21.0 aiohappyeyeballs-2.4.3 aiohttp-3.10.9 aiohttp-cors-0.7.0 aiosignal-1.3.1 antlr4-python3-runtime-4.9.3 async-timeout-4.0.3 autogluon-1.1.1 autogluon.common-1.1.1 autogluon.core-1.1.1 autogluon.features-1.1.1 autogluon.multimodal-1.1.1 autogluon.tabular-1.1.1 autogluon.timeseries-1.1.1 boto3-1.35.34 botocore-1.35.34 catboost-1.2.7 colorama-0.4.6 coloredlogs-15.0.1 colorful-0.5.6 datasets-3.0.1 dill-0.3.8 distlib-0.3.8 evaluate-0.4.3 frozenlist-1.4.1 fsspec-2024.6.1 future-1.0.0 gluonts-0.15.1 graphviz-0.20.3 humanfriendly-10.0 hyperopt-0.2.7 jmespath-1.0.1 jsonschema-4.21.1 lightgbm-4.3.0 lightning-2.3.3 lightning-utilities-0.11.7 mlforecast-0.10.0 model-index-0.1.11 multidict-6.1.0 multiprocess-0.70.16 nlpaug-1.1.11 nptyping-2.4.1 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-ml-py3-7.352.0 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.6.77 nvidia-nvtx-cu12-12.1.105 omegaconf-2.2.3 onnx-1.17.0 onnxruntime-1.19.2 opencensus-0.11.4 opencensus-context-0.1.3 opendatalab-0.0.10 openmim-0.3.9 openxlab-0.0.11 optimum-1.18.1 ordered-set-4.1.0 orjson-3.10.7 patsy-0.5.6 pdf2image-1.17.0 py-spy-0.3.14 py4j-0.10.9.7 pycryptodome-3.21.0 pytesseract-0.3.10 pytorch-lightning-2.3.3 pytorch-metric-learning-2.3.0 ray-2.10.0 s3transfer-0.10.2 scikit-image-0.20.0 scikit-learn-1.4.0 scipy-1.12.0 seqeval-1.2.2 statsforecast-1.4.0 statsmodels-0.14.4 tabulate-0.9.0 tensorboardX-2.6.2.2 timm-0.9.16 tokenizers-0.15.2 torch-2.3.1 torchmetrics-1.2.1 torchvision-0.18.1 transformers-4.39.3 triton-2.3.1 utilsforecast-0.0.10 virtualenv-20.26.6 window-ops-0.0.15 xgboost-2.0.3 xxhash-3.5.0 yarl-1.13.1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "pydevd_plugins"
                ]
              },
              "id": "bee2c63426ef4112828f67a5791dc477"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Install AutoGluon library for tabular data prediction\n",
        "!pip install autogluon"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install the Kaggle package to enable Kaggle API functionality\n",
        "!pip install kaggle"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3fcyj4azPVhA",
        "outputId": "5d4e6bfd-9208-43ef-d44e-4b0edc36db5d"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.10/dist-packages (1.6.17)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.10/dist-packages (from kaggle) (1.16.0)\n",
            "Requirement already satisfied: certifi>=2023.7.22 in /usr/local/lib/python3.10/dist-packages (from kaggle) (2024.8.30)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.9.0.post0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from kaggle) (4.66.5)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.10/dist-packages (from kaggle) (8.0.4)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.2.3)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from kaggle) (6.1.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->kaggle) (0.5.1)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.10/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (3.10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Upload the kaggle.json file to Colab\n",
        "from google.colab import files\n",
        "files.upload()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "id": "ZqaF4B4HR7Cv",
        "outputId": "0fab6d35-9d26-4272-9c65-9c1685f7faa5"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-d9f6ce7a-be18-4560-9be5-a0a3c0ae4923\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-d9f6ce7a-be18-4560-9be5-a0a3c0ae4923\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving kaggle.json to kaggle.json\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'kaggle.json': b'{\"username\":\"subhashpolisetti347\",\"key\":\"0590675aeb1ac3bbbb4f3b6a4ac2e351\"}'}"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the Kaggle directory if it doesn't exist\n",
        "!mkdir -p ~/.kaggle\n",
        "\n",
        "# Move the kaggle.json file to this directory\n",
        "!mv kaggle.json ~/.kaggle/\n",
        "\n",
        "# Set the required permissions for the file\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "x6-HAsqGSBi9"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Download the IEEE-CIS Fraud Detection dataset from Kaggle\n",
        "!kaggle competitions download -c ieee-fraud-detection\n",
        "\n",
        "# Unzip the dataset\n",
        "!unzip ieee-fraud-detection.zip\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FDq8RuJISB9o",
        "outputId": "783601de-f04b-4f78-fa21-d5199003160b"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading ieee-fraud-detection.zip to /content\n",
            " 95% 112M/118M [00:00<00:00, 153MB/s] \n",
            "100% 118M/118M [00:00<00:00, 154MB/s]\n",
            "Archive:  ieee-fraud-detection.zip\n",
            "  inflating: sample_submission.csv   \n",
            "  inflating: test_identity.csv       \n",
            "  inflating: test_transaction.csv    \n",
            "  inflating: train_identity.csv      \n",
            "  inflating: train_transaction.csv   \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Directory where the unzipped CSV files are located\n",
        "directory = '/content/'\n",
        "\n",
        "# Load the transaction and identity datasets\n",
        "train_identity = pd.read_csv(directory+'train_identity.csv')\n",
        "train_transaction = pd.read_csv(directory+'train_transaction.csv')\n",
        "\n",
        "# Merge the two datasets on 'TransactionID'\n",
        "train_data = pd.merge(train_transaction, train_identity, on='TransactionID', how='left')\n",
        "\n",
        "# Check the first few rows to ensure data is loaded correctly\n",
        "train_data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 290
        },
        "id": "rF6nKoqKSEEp",
        "outputId": "4739b0aa-8e74-4f56-e14f-7c5f731ffdf7"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   TransactionID  isFraud  TransactionDT  TransactionAmt ProductCD  card1  \\\n",
              "0        2987000        0          86400            68.5         W  13926   \n",
              "1        2987001        0          86401            29.0         W   2755   \n",
              "2        2987002        0          86469            59.0         W   4663   \n",
              "3        2987003        0          86499            50.0         W  18132   \n",
              "4        2987004        0          86506            50.0         H   4497   \n",
              "\n",
              "   card2  card3       card4  card5  ...                id_31  id_32  \\\n",
              "0    NaN  150.0    discover  142.0  ...                  NaN    NaN   \n",
              "1  404.0  150.0  mastercard  102.0  ...                  NaN    NaN   \n",
              "2  490.0  150.0        visa  166.0  ...                  NaN    NaN   \n",
              "3  567.0  150.0  mastercard  117.0  ...                  NaN    NaN   \n",
              "4  514.0  150.0  mastercard  102.0  ...  samsung browser 6.2   32.0   \n",
              "\n",
              "       id_33           id_34  id_35 id_36 id_37  id_38  DeviceType  \\\n",
              "0        NaN             NaN    NaN   NaN   NaN    NaN         NaN   \n",
              "1        NaN             NaN    NaN   NaN   NaN    NaN         NaN   \n",
              "2        NaN             NaN    NaN   NaN   NaN    NaN         NaN   \n",
              "3        NaN             NaN    NaN   NaN   NaN    NaN         NaN   \n",
              "4  2220x1080  match_status:2      T     F     T      T      mobile   \n",
              "\n",
              "                      DeviceInfo  \n",
              "0                            NaN  \n",
              "1                            NaN  \n",
              "2                            NaN  \n",
              "3                            NaN  \n",
              "4  SAMSUNG SM-G892A Build/NRD90M  \n",
              "\n",
              "[5 rows x 434 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-475eaf88-e0dc-4253-9da0-bba16e0e9a84\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>TransactionID</th>\n",
              "      <th>isFraud</th>\n",
              "      <th>TransactionDT</th>\n",
              "      <th>TransactionAmt</th>\n",
              "      <th>ProductCD</th>\n",
              "      <th>card1</th>\n",
              "      <th>card2</th>\n",
              "      <th>card3</th>\n",
              "      <th>card4</th>\n",
              "      <th>card5</th>\n",
              "      <th>...</th>\n",
              "      <th>id_31</th>\n",
              "      <th>id_32</th>\n",
              "      <th>id_33</th>\n",
              "      <th>id_34</th>\n",
              "      <th>id_35</th>\n",
              "      <th>id_36</th>\n",
              "      <th>id_37</th>\n",
              "      <th>id_38</th>\n",
              "      <th>DeviceType</th>\n",
              "      <th>DeviceInfo</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2987000</td>\n",
              "      <td>0</td>\n",
              "      <td>86400</td>\n",
              "      <td>68.5</td>\n",
              "      <td>W</td>\n",
              "      <td>13926</td>\n",
              "      <td>NaN</td>\n",
              "      <td>150.0</td>\n",
              "      <td>discover</td>\n",
              "      <td>142.0</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2987001</td>\n",
              "      <td>0</td>\n",
              "      <td>86401</td>\n",
              "      <td>29.0</td>\n",
              "      <td>W</td>\n",
              "      <td>2755</td>\n",
              "      <td>404.0</td>\n",
              "      <td>150.0</td>\n",
              "      <td>mastercard</td>\n",
              "      <td>102.0</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2987002</td>\n",
              "      <td>0</td>\n",
              "      <td>86469</td>\n",
              "      <td>59.0</td>\n",
              "      <td>W</td>\n",
              "      <td>4663</td>\n",
              "      <td>490.0</td>\n",
              "      <td>150.0</td>\n",
              "      <td>visa</td>\n",
              "      <td>166.0</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2987003</td>\n",
              "      <td>0</td>\n",
              "      <td>86499</td>\n",
              "      <td>50.0</td>\n",
              "      <td>W</td>\n",
              "      <td>18132</td>\n",
              "      <td>567.0</td>\n",
              "      <td>150.0</td>\n",
              "      <td>mastercard</td>\n",
              "      <td>117.0</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2987004</td>\n",
              "      <td>0</td>\n",
              "      <td>86506</td>\n",
              "      <td>50.0</td>\n",
              "      <td>H</td>\n",
              "      <td>4497</td>\n",
              "      <td>514.0</td>\n",
              "      <td>150.0</td>\n",
              "      <td>mastercard</td>\n",
              "      <td>102.0</td>\n",
              "      <td>...</td>\n",
              "      <td>samsung browser 6.2</td>\n",
              "      <td>32.0</td>\n",
              "      <td>2220x1080</td>\n",
              "      <td>match_status:2</td>\n",
              "      <td>T</td>\n",
              "      <td>F</td>\n",
              "      <td>T</td>\n",
              "      <td>T</td>\n",
              "      <td>mobile</td>\n",
              "      <td>SAMSUNG SM-G892A Build/NRD90M</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 434 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-475eaf88-e0dc-4253-9da0-bba16e0e9a84')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-475eaf88-e0dc-4253-9da0-bba16e0e9a84 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-475eaf88-e0dc-4253-9da0-bba16e0e9a84');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-11494905-57c2-4544-85c8-53bd9d44b7db\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-11494905-57c2-4544-85c8-53bd9d44b7db')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-11494905-57c2-4544-85c8-53bd9d44b7db button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "train_data"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from autogluon.tabular import TabularPredictor\n",
        "\n",
        "# Define the target label and evaluation metric\n",
        "label = 'isFraud'\n",
        "eval_metric = 'roc_auc'\n",
        "\n",
        "# Define the save path for AutoGluon models\n",
        "save_path = '/content/AutoGluonModels/'\n",
        "\n",
        "# Train the model with AutoGluon\n",
        "predictor = TabularPredictor(label=label, eval_metric=eval_metric, path=save_path, verbosity=3).fit(\n",
        "    train_data, presets='good_quality', time_limit=3600, excluded_model_types=['NN', 'STACKER'], keep_only_best=True\n",
        ")\n",
        "\n",
        "# Print the summary of the fit process\n",
        "results = predictor.fit_summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dAgyH8hNSHq_",
        "outputId": "bdf1f6a9-a76a-4723-a2b1-8e007e9f1e18"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Verbosity: 3 (Detailed Logging)\n",
            "=================== System Info ===================\n",
            "AutoGluon Version:  1.1.1\n",
            "Python Version:     3.10.12\n",
            "Operating System:   Linux\n",
            "Platform Machine:   x86_64\n",
            "Platform Version:   #1 SMP PREEMPT_DYNAMIC Thu Jun 27 21:05:47 UTC 2024\n",
            "CPU Count:          96\n",
            "GPU Count:          0\n",
            "Memory Avail:       324.49 GB / 334.56 GB (97.0%)\n",
            "Disk Space Avail:   197.25 GB / 225.33 GB (87.5%)\n",
            "===================================================\n",
            "Presets specified: ['good_quality']\n",
            "============ fit kwarg info ============\n",
            "User Specified kwargs:\n",
            "{'auto_stack': True,\n",
            " 'excluded_model_types': ['NN', 'STACKER'],\n",
            " 'keep_only_best': True,\n",
            " 'num_bag_sets': 1,\n",
            " 'refit_full': True,\n",
            " 'save_bag_folds': False,\n",
            " 'set_best_to_refit_full': True}\n",
            "Full kwargs:\n",
            "{'_feature_generator_kwargs': None,\n",
            " '_save_bag_folds': None,\n",
            " 'ag_args': None,\n",
            " 'ag_args_ensemble': None,\n",
            " 'ag_args_fit': None,\n",
            " 'auto_stack': True,\n",
            " 'calibrate': 'auto',\n",
            " 'ds_args': {'clean_up_fits': True,\n",
            "             'detection_time_frac': 0.25,\n",
            "             'enable_ray_logging': True,\n",
            "             'holdout_data': None,\n",
            "             'holdout_frac': 0.1111111111111111,\n",
            "             'memory_safe_fits': True,\n",
            "             'n_folds': 2,\n",
            "             'n_repeats': 1,\n",
            "             'validation_procedure': 'holdout'},\n",
            " 'excluded_model_types': ['NN', 'STACKER'],\n",
            " 'feature_generator': 'auto',\n",
            " 'feature_prune_kwargs': None,\n",
            " 'holdout_frac': None,\n",
            " 'hyperparameter_tune_kwargs': None,\n",
            " 'included_model_types': None,\n",
            " 'keep_only_best': True,\n",
            " 'name_suffix': None,\n",
            " 'num_bag_folds': None,\n",
            " 'num_bag_sets': 1,\n",
            " 'num_stack_levels': None,\n",
            " 'pseudo_data': None,\n",
            " 'refit_full': True,\n",
            " 'save_bag_folds': False,\n",
            " 'save_space': False,\n",
            " 'set_best_to_refit_full': True,\n",
            " 'unlabeled_data': None,\n",
            " 'use_bag_holdout': False,\n",
            " 'verbosity': 3}\n",
            "========================================\n",
            "Setting dynamic_stacking from 'auto' to True. Reason: Enable dynamic_stacking when use_bag_holdout is disabled. (use_bag_holdout=False)\n",
            "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=1\n",
            "Note: `save_bag_folds=False`! This will greatly reduce peak disk usage during fit (by ~8x), but runs the risk of an out-of-memory error during model refit if memory is small relative to the data size.\n",
            "\tYou can avoid this risk by setting `save_bag_folds=True`.\n",
            "DyStack is enabled (dynamic_stacking=True). AutoGluon will try to determine whether the input data is affected by stacked overfitting and enable or disable stacking as a consequence.\n",
            "\tThis is used to identify the optimal `num_stack_levels` value. Copies of AutoGluon will be fit on subsets of the data. Then holdout validation data is used to detect stacked overfitting.\n",
            "\tRunning DyStack for up to 900s of the 3600s of remaining time (25%).\n",
            "\tRunning DyStack sub-fit in a ray process to avoid memory leakage. Enabling ray logging (enable_ray_logging=True). Specify `ds_args={'enable_ray_logging': False}` if you experience logging issues.\n",
            "2024-10-07 18:21:20,160\tINFO worker.py:1743 -- Started a local Ray instance. View the dashboard at \u001b[1m\u001b[32m127.0.0.1:8265 \u001b[39m\u001b[22m\n",
            "\t\tContext path: \"/content/AutoGluonModels/ds_sub_fit/sub_fit_ho\"\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m Running DyStack sub-fit ...\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m Saving /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/learner.pkl\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m Saving /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/predictor.pkl\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m Beginning AutoGluon training ... Time limit = 895s\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m AutoGluon will save models to \"/content/AutoGluonModels/ds_sub_fit/sub_fit_ho\"\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m Train Data Rows:    524924\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m Train Data Columns: 433\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m Label Column:       isFraud\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m Problem Type:       binary\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m Preprocessing data ...\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m Selected class <--> label mapping:  class 1 = 1, class 0 = 0\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m Using Feature Generators to preprocess the data ...\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m Fitting AutoMLPipelineFeatureGenerator...\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m \tAvailable Memory:                    327362.89 MB\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m \tTrain Data (Original)  Memory Usage: 2278.50 MB (0.7% of available memory)\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m \tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m \tStage 1 Generators:\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m \t\tFitting AsTypeFeatureGenerator...\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m \t\t\tOriginal Features (exact raw dtype, raw dtype):\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m \t\t\t\t('float64', 'float') : 399 | ['TransactionAmt', 'card2', 'card3', 'card5', 'addr1', ...]\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m \t\t\t\t('int64', 'int')     :   3 | ['TransactionID', 'TransactionDT', 'card1']\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m \t\t\t\t('object', 'object') :  31 | ['ProductCD', 'card4', 'card6', 'P_emaildomain', 'R_emaildomain', ...]\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m \t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m \t\t\t\t('float', [])  : 399 | ['TransactionAmt', 'card2', 'card3', 'card5', 'addr1', ...]\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m \t\t\t\t('int', [])    :   3 | ['TransactionID', 'TransactionDT', 'card1']\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m \t\t\t\t('object', []) :  31 | ['ProductCD', 'card4', 'card6', 'P_emaildomain', 'R_emaildomain', ...]\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m \t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m \t\t\t\t('float', [])  : 399 | ['TransactionAmt', 'card2', 'card3', 'card5', 'addr1', ...]\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m \t\t\t\t('int', [])    :   3 | ['TransactionID', 'TransactionDT', 'card1']\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m \t\t\t\t('object', []) :  31 | ['ProductCD', 'card4', 'card6', 'P_emaildomain', 'R_emaildomain', ...]\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m \t\t\t4.9s = Fit runtime\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m \t\t\t433 features in original data used to generate 433 features in processed data.\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m \tStage 2 Generators:\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m \t\tFitting FillNaFeatureGenerator...\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m \t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m \t\t\t\t('float', [])  : 399 | ['TransactionAmt', 'card2', 'card3', 'card5', 'addr1', ...]\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m \t\t\t\t('int', [])    :   3 | ['TransactionID', 'TransactionDT', 'card1']\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m \t\t\t\t('object', []) :  31 | ['ProductCD', 'card4', 'card6', 'P_emaildomain', 'R_emaildomain', ...]\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m \t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m \t\t\t\t('float', [])  : 399 | ['TransactionAmt', 'card2', 'card3', 'card5', 'addr1', ...]\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m \t\t\t\t('int', [])    :   3 | ['TransactionID', 'TransactionDT', 'card1']\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m \t\t\t\t('object', []) :  31 | ['ProductCD', 'card4', 'card6', 'P_emaildomain', 'R_emaildomain', ...]\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m \t\t\t3.9s = Fit runtime\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m \t\t\t433 features in original data used to generate 433 features in processed data.\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m \tStage 3 Generators:\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m \t\tFitting IdentityFeatureGenerator...\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m \t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m \t\t\t\t('float', []) : 399 | ['TransactionAmt', 'card2', 'card3', 'card5', 'addr1', ...]\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m \t\t\t\t('int', [])   :   3 | ['TransactionID', 'TransactionDT', 'card1']\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m \t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m \t\t\t\t('float', []) : 399 | ['TransactionAmt', 'card2', 'card3', 'card5', 'addr1', ...]\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m \t\t\t\t('int', [])   :   3 | ['TransactionID', 'TransactionDT', 'card1']\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m \t\t\t0.7s = Fit runtime\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m \t\t\t402 features in original data used to generate 402 features in processed data.\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m \t\tFitting CategoryFeatureGenerator...\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m \t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m \t\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m \t\t\t\t\t('category', []) : 31 | ['ProductCD', 'card4', 'card6', 'P_emaildomain', 'R_emaildomain', ...]\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m \t\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m \t\t\t\t\t('category', []) : 31 | ['ProductCD', 'card4', 'card6', 'P_emaildomain', 'R_emaildomain', ...]\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m \t\t\t\t0.1s = Fit runtime\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m \t\t\t\t31 features in original data used to generate 31 features in processed data.\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m \t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m \t\t\t\t('object', []) : 31 | ['ProductCD', 'card4', 'card6', 'P_emaildomain', 'R_emaildomain', ...]\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m \t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m \t\t\t\t('category', []) : 31 | ['ProductCD', 'card4', 'card6', 'P_emaildomain', 'R_emaildomain', ...]\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m \t\t\t1.0s = Fit runtime\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m \t\t\t31 features in original data used to generate 31 features in processed data.\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m \t\tSkipping DatetimeFeatureGenerator: No input feature with required dtypes.\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m \t\tSkipping TextSpecialFeatureGenerator: No input feature with required dtypes.\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m \t\tSkipping TextNgramFeatureGenerator: No input feature with required dtypes.\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m \t\tSkipping IdentityFeatureGenerator: No input feature with required dtypes.\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m \t\tSkipping IsNanFeatureGenerator: No input feature with required dtypes.\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m \tStage 4 Generators:\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m \t\tFitting DropUniqueFeatureGenerator...\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m \t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m \t\t\t\t('category', []) :  31 | ['ProductCD', 'card4', 'card6', 'P_emaildomain', 'R_emaildomain', ...]\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m \t\t\t\t('float', [])    : 399 | ['TransactionAmt', 'card2', 'card3', 'card5', 'addr1', ...]\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m \t\t\t\t('int', [])      :   3 | ['TransactionID', 'TransactionDT', 'card1']\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m \t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m \t\t\t\t('category', []) :  31 | ['ProductCD', 'card4', 'card6', 'P_emaildomain', 'R_emaildomain', ...]\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m \t\t\t\t('float', [])    : 399 | ['TransactionAmt', 'card2', 'card3', 'card5', 'addr1', ...]\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m \t\t\t\t('int', [])      :   3 | ['TransactionID', 'TransactionDT', 'card1']\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m \t\t\t3.4s = Fit runtime\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m \t\t\t433 features in original data used to generate 433 features in processed data.\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m \tStage 5 Generators:\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m \t\tFitting DropDuplicatesFeatureGenerator...\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m \t\t\t4 duplicate columns removed: ['V16', 'V28', 'V119', 'V241']\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m \t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m \t\t\t\t('category', []) :  31 | ['ProductCD', 'card4', 'card6', 'P_emaildomain', 'R_emaildomain', ...]\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m \t\t\t\t('float', [])    : 395 | ['TransactionAmt', 'card2', 'card3', 'card5', 'addr1', ...]\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m \t\t\t\t('int', [])      :   3 | ['TransactionID', 'TransactionDT', 'card1']\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m \t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m \t\t\t\t('category', []) :  31 | ['ProductCD', 'card4', 'card6', 'P_emaildomain', 'R_emaildomain', ...]\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m \t\t\t\t('float', [])    : 395 | ['TransactionAmt', 'card2', 'card3', 'card5', 'addr1', ...]\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m \t\t\t\t('int', [])      :   3 | ['TransactionID', 'TransactionDT', 'card1']\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m \t\t\t4.3s = Fit runtime\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m \t\t\t429 features in original data used to generate 429 features in processed data.\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m \tUnused Original Features (Count: 4): ['V16', 'V28', 'V119', 'V241']\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m \t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m \t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m \t\tThese features do not need to be present at inference time.\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m \t\t('float', []) : 4 | ['V16', 'V28', 'V119', 'V241']\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m \tTypes of features in original data (exact raw dtype, raw dtype):\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m \t\t('float64', 'float') : 395 | ['TransactionAmt', 'card2', 'card3', 'card5', 'addr1', ...]\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m \t\t('int64', 'int')     :   3 | ['TransactionID', 'TransactionDT', 'card1']\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m \t\t('object', 'object') :  31 | ['ProductCD', 'card4', 'card6', 'P_emaildomain', 'R_emaildomain', ...]\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m \tTypes of features in original data (raw dtype, special dtypes):\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m \t\t('float', [])  : 395 | ['TransactionAmt', 'card2', 'card3', 'card5', 'addr1', ...]\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m \t\t('int', [])    :   3 | ['TransactionID', 'TransactionDT', 'card1']\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m \t\t('object', []) :  31 | ['ProductCD', 'card4', 'card6', 'P_emaildomain', 'R_emaildomain', ...]\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m \tTypes of features in processed data (exact raw dtype, raw dtype):\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m \t\t('category', 'category') :  31 | ['ProductCD', 'card4', 'card6', 'P_emaildomain', 'R_emaildomain', ...]\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m \t\t('float64', 'float')     : 395 | ['TransactionAmt', 'card2', 'card3', 'card5', 'addr1', ...]\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m \t\t('int64', 'int')         :   3 | ['TransactionID', 'TransactionDT', 'card1']\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m \tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m \t\t('category', []) :  31 | ['ProductCD', 'card4', 'card6', 'P_emaildomain', 'R_emaildomain', ...]\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m \t\t('float', [])    : 395 | ['TransactionAmt', 'card2', 'card3', 'card5', 'addr1', ...]\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m \t\t('int', [])      :   3 | ['TransactionID', 'TransactionDT', 'card1']\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m \t27.8s = Fit runtime\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m \t429 features in original data used to generate 429 features in processed data.\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m \tTrain Data (Processed) Memory Usage: 1610.46 MB (0.5% of available memory)\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m Data preprocessing and feature engineering runtime = 33.56s ...\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m AutoGluon will gauge predictive performance using evaluation metric: 'roc_auc'\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m \tThis metric expects predicted probabilities rather than predicted class labels, so you'll need to use predict_proba() instead of predict()\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m \tTo change this, specify the eval_metric parameter of Predictor()\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m Saving /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/learner.pkl\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m User-specified model hyperparameters to be fit:\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m {\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m \t'NN_TORCH': {},\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m \t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m \t'CAT': {},\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m \t'XGB': {},\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m \t'FASTAI': {},\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m \t'RF': [{'criterion': 'gini', 'max_depth': 15, 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'max_depth': 15, 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'max_depth': 15, 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m \t'XT': [{'criterion': 'gini', 'max_depth': 15, 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'max_depth': 15, 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'max_depth': 15, 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m }\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m Saving /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/utils/data/X.pkl\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m Saving /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/utils/data/y.pkl\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m Excluded models: [] (Specified by `excluded_model_types`)\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m Model configs that will be trained (in order):\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m \tLightGBMXT_BAG_L1: \t{'extra_trees': True, 'ag_args': {'name_suffix': 'XT', 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>, 'priority': 90}, 'ag_args_ensemble': {'save_bag_folds': False}}\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m \tLightGBM_BAG_L1: \t{'ag_args': {'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>, 'priority': 90}, 'ag_args_ensemble': {'save_bag_folds': False}}\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m \tRandomForestGini_BAG_L1: \t{'criterion': 'gini', 'max_depth': 15, 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass'], 'model_type': <class 'autogluon.tabular.models.rf.rf_model.RFModel'>, 'priority': 80}, 'ag_args_ensemble': {'use_child_oof': True, 'save_bag_folds': False}}\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m \tRandomForestEntr_BAG_L1: \t{'criterion': 'entropy', 'max_depth': 15, 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass'], 'model_type': <class 'autogluon.tabular.models.rf.rf_model.RFModel'>, 'priority': 80}, 'ag_args_ensemble': {'use_child_oof': True, 'save_bag_folds': False}}\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m \tCatBoost_BAG_L1: \t{'ag_args': {'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>, 'priority': 70}, 'ag_args_ensemble': {'save_bag_folds': False}}\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m \tExtraTreesGini_BAG_L1: \t{'criterion': 'gini', 'max_depth': 15, 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass'], 'model_type': <class 'autogluon.tabular.models.xt.xt_model.XTModel'>, 'priority': 60}, 'ag_args_ensemble': {'use_child_oof': True, 'save_bag_folds': False}}\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m \tExtraTreesEntr_BAG_L1: \t{'criterion': 'entropy', 'max_depth': 15, 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass'], 'model_type': <class 'autogluon.tabular.models.xt.xt_model.XTModel'>, 'priority': 60}, 'ag_args_ensemble': {'use_child_oof': True, 'save_bag_folds': False}}\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m \tNeuralNetFastAI_BAG_L1: \t{'ag_args': {'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>, 'priority': 50}, 'ag_args_ensemble': {'save_bag_folds': False}}\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m \tXGBoost_BAG_L1: \t{'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'softclass'], 'model_type': <class 'autogluon.tabular.models.xgboost.xgboost_model.XGBoostModel'>, 'priority': 40}, 'ag_args_ensemble': {'save_bag_folds': False}}\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m \tNeuralNetTorch_BAG_L1: \t{'ag_args': {'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>, 'priority': 25}, 'ag_args_ensemble': {'save_bag_folds': False}}\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m \tLightGBMLarge_BAG_L1: \t{'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 5, 'ag_args': {'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>, 'name_suffix': 'Large', 'hyperparameter_tune_kwargs': None, 'priority': 0}, 'ag_args_ensemble': {'save_bag_folds': False}}\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m Fitting 11 L1 models ...\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 574.45s of the 861.89s of remaining time.\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m \tFitting LightGBMXT_BAG_L1 with 'num_gpus': 0, 'num_cpus': 96\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m Saving /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/LightGBMXT_BAG_L1/utils/model_template.pkl\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m Loading: /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/LightGBMXT_BAG_L1/utils/model_template.pkl\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=12, gpus=0, memory=3.25%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(_ray_fit pid=16505)\u001b[0m [50]\tvalid_set's binary_logloss: 0.0964283\n",
            "\u001b[36m(_ray_fit pid=16508)\u001b[0m [100]\tvalid_set's binary_logloss: 0.0852749\u001b[32m [repeated 10x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/ray-logging.html#log-deduplication for more options.)\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=16504)\u001b[0m [150]\tvalid_set's binary_logloss: 0.0826913\u001b[32m [repeated 12x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=16507)\u001b[0m [250]\tvalid_set's binary_logloss: 0.077055\u001b[32m [repeated 12x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=16509)\u001b[0m [300]\tvalid_set's binary_logloss: 0.0745371\u001b[32m [repeated 11x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=16505)\u001b[0m [400]\tvalid_set's binary_logloss: 0.072224\u001b[32m [repeated 13x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=16506)\u001b[0m [500]\tvalid_set's binary_logloss: 0.0668289\u001b[32m [repeated 14x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=16508)\u001b[0m [600]\tvalid_set's binary_logloss: 0.0649414\u001b[32m [repeated 14x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=16510)\u001b[0m [600]\tvalid_set's binary_logloss: 0.065767\u001b[32m [repeated 13x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=16509)\u001b[0m [700]\tvalid_set's binary_logloss: 0.0654168\u001b[32m [repeated 13x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=16504)\u001b[0m [850]\tvalid_set's binary_logloss: 0.0645864\u001b[32m [repeated 16x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=16504)\u001b[0m [950]\tvalid_set's binary_logloss: 0.0633608\u001b[32m [repeated 14x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=16509)\u001b[0m [950]\tvalid_set's binary_logloss: 0.0623705\u001b[32m [repeated 13x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=16506)\u001b[0m [1150]\tvalid_set's binary_logloss: 0.0580384\u001b[32m [repeated 13x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=16506)\u001b[0m [1250]\tvalid_set's binary_logloss: 0.0571161\u001b[32m [repeated 14x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=16506)\u001b[0m [1350]\tvalid_set's binary_logloss: 0.0563431\u001b[32m [repeated 15x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=16506)\u001b[0m [1450]\tvalid_set's binary_logloss: 0.0556229\u001b[32m [repeated 15x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=16507)\u001b[0m [1400]\tvalid_set's binary_logloss: 0.0586168\u001b[32m [repeated 13x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=16507)\u001b[0m [1500]\tvalid_set's binary_logloss: 0.05792\u001b[32m [repeated 14x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=16507)\u001b[0m [1600]\tvalid_set's binary_logloss: 0.0571644\u001b[32m [repeated 16x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=16505)\u001b[0m [1750]\tvalid_set's binary_logloss: 0.0570544\u001b[32m [repeated 16x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=16506)\u001b[0m [1900]\tvalid_set's binary_logloss: 0.0531257\u001b[32m [repeated 15x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=16509)\u001b[0m [1850]\tvalid_set's binary_logloss: 0.0557836\u001b[32m [repeated 15x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=16508)\u001b[0m [2000]\tvalid_set's binary_logloss: 0.0528039\u001b[32m [repeated 15x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=16507)\u001b[0m [2050]\tvalid_set's binary_logloss: 0.0546059\u001b[32m [repeated 15x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=16504)\u001b[0m [2250]\tvalid_set's binary_logloss: 0.0548266\u001b[32m [repeated 14x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=16510)\u001b[0m [2250]\tvalid_set's binary_logloss: 0.0521238\u001b[32m [repeated 14x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=16506)\u001b[0m [2450]\tvalid_set's binary_logloss: 0.0507143\u001b[32m [repeated 15x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=16506)\u001b[0m [2550]\tvalid_set's binary_logloss: 0.0503668\u001b[32m [repeated 15x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=16508)\u001b[0m [2550]\tvalid_set's binary_logloss: 0.0505254\u001b[32m [repeated 15x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=16507)\u001b[0m [2600]\tvalid_set's binary_logloss: 0.0523246\u001b[32m [repeated 14x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=16510)\u001b[0m [2700]\tvalid_set's binary_logloss: 0.0505905\u001b[32m [repeated 15x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=16510)\u001b[0m [2800]\tvalid_set's binary_logloss: 0.0502946\u001b[32m [repeated 16x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=16503)\u001b[0m [2800]\tvalid_set's binary_logloss: 0.0497505\u001b[32m [repeated 14x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=16505)\u001b[0m [3050]\tvalid_set's binary_logloss: 0.0518548\u001b[32m [repeated 14x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=16508)\u001b[0m [3100]\tvalid_set's binary_logloss: 0.0490202\u001b[32m [repeated 14x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=16506)\u001b[0m [3300]\tvalid_set's binary_logloss: 0.0482581\u001b[32m [repeated 15x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=16506)\u001b[0m [3400]\tvalid_set's binary_logloss: 0.0480193\u001b[32m [repeated 16x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=16506)\u001b[0m [3500]\tvalid_set's binary_logloss: 0.0477454\u001b[32m [repeated 16x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=16509)\u001b[0m [3500]\tvalid_set's binary_logloss: 0.050254\u001b[32m [repeated 15x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=16509)\u001b[0m [3600]\tvalid_set's binary_logloss: 0.0500346\u001b[32m [repeated 14x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=16508)\u001b[0m [3650]\tvalid_set's binary_logloss: 0.0477042\u001b[32m [repeated 16x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=16508)\u001b[0m [3750]\tvalid_set's binary_logloss: 0.0475577\u001b[32m [repeated 14x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=16507)\u001b[0m [3800]\tvalid_set's binary_logloss: 0.0491141\u001b[32m [repeated 14x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=16503)\u001b[0m [3800]\tvalid_set's binary_logloss: 0.0474315\u001b[32m [repeated 13x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=16510)\u001b[0m [4000]\tvalid_set's binary_logloss: 0.0477298\u001b[32m [repeated 16x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=16510)\u001b[0m [4100]\tvalid_set's binary_logloss: 0.0475528\u001b[32m [repeated 15x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=16510)\u001b[0m [4200]\tvalid_set's binary_logloss: 0.047408\u001b[32m [repeated 16x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=16505)\u001b[0m [4350]\tvalid_set's binary_logloss: 0.0491402\u001b[32m [repeated 15x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=16504)\u001b[0m [4400]\tvalid_set's binary_logloss: 0.0496127\u001b[32m [repeated 14x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=16506)\u001b[0m [4600]\tvalid_set's binary_logloss: 0.0459843\u001b[32m [repeated 15x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=16503)\u001b[0m [4450]\tvalid_set's binary_logloss: 0.0463754\u001b[32m [repeated 14x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=16510)\u001b[0m [4650]\tvalid_set's binary_logloss: 0.0468538\u001b[32m [repeated 14x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=16508)\u001b[0m [4800]\tvalid_set's binary_logloss: 0.0461684\u001b[32m [repeated 15x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=16508)\u001b[0m [4900]\tvalid_set's binary_logloss: 0.0461347\u001b[32m [repeated 16x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=16508)\u001b[0m [5000]\tvalid_set's binary_logloss: 0.046019\u001b[32m [repeated 16x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=16508)\u001b[0m [5100]\tvalid_set's binary_logloss: 0.0459619\u001b[32m [repeated 16x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=16508)\u001b[0m [5200]\tvalid_set's binary_logloss: 0.0458736\u001b[32m [repeated 16x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=16506)\u001b[0m [5400]\tvalid_set's binary_logloss: 0.0452323\u001b[32m [repeated 16x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=16506)\u001b[0m [5500]\tvalid_set's binary_logloss: 0.0451698\u001b[32m [repeated 16x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=16509)\u001b[0m [5500]\tvalid_set's binary_logloss: 0.0479893\u001b[32m [repeated 13x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=16504)\u001b[0m [5550]\tvalid_set's binary_logloss: 0.0486186\u001b[32m [repeated 15x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=16505)\u001b[0m [5650]\tvalid_set's binary_logloss: 0.0479285\u001b[32m [repeated 14x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=16505)\u001b[0m [5750]\tvalid_set's binary_logloss: 0.0478927\u001b[32m [repeated 16x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=16504)\u001b[0m [5850]\tvalid_set's binary_logloss: 0.0485214\u001b[32m [repeated 15x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=16504)\u001b[0m [5950]\tvalid_set's binary_logloss: 0.04845\u001b[32m [repeated 15x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=16507)\u001b[0m [5950]\tvalid_set's binary_logloss: 0.0466161\u001b[32m [repeated 15x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=16503)\u001b[0m [5950]\tvalid_set's binary_logloss: 0.0450772\u001b[32m [repeated 13x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=16506)\u001b[0m [6350]\tvalid_set's binary_logloss: 0.0447212\u001b[32m [repeated 15x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=16510)\u001b[0m [6250]\tvalid_set's binary_logloss: 0.0458979\u001b[32m [repeated 15x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=16504)\u001b[0m [6400]\tvalid_set's binary_logloss: 0.0483327\u001b[32m [repeated 15x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=16509)\u001b[0m [6500]\tvalid_set's binary_logloss: 0.0476941\u001b[32m [repeated 14x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=16503)\u001b[0m [6400]\tvalid_set's binary_logloss: 0.0449243\u001b[32m [repeated 15x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=16503)\u001b[0m [6500]\tvalid_set's binary_logloss: 0.0448888\u001b[32m [repeated 16x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=16506)\u001b[0m [6900]\tvalid_set's binary_logloss: 0.0446328\u001b[32m [repeated 13x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=16506)\u001b[0m [7000]\tvalid_set's binary_logloss: 0.0445845\u001b[32m [repeated 14x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=16506)\u001b[0m [7100]\tvalid_set's binary_logloss: 0.0445817\u001b[32m [repeated 16x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=16506)\u001b[0m [7200]\tvalid_set's binary_logloss: 0.044577\u001b[32m [repeated 17x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=16506)\u001b[0m [7300]\tvalid_set's binary_logloss: 0.0445663\u001b[32m [repeated 15x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=16506)\u001b[0m [7400]\tvalid_set's binary_logloss: 0.0445538\u001b[32m [repeated 16x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=16503)\u001b[0m [7150]\tvalid_set's binary_logloss: 0.0448075\u001b[32m [repeated 14x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=16505)\u001b[0m [7400]\tvalid_set's binary_logloss: 0.0475705\u001b[32m [repeated 14x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=16505)\u001b[0m [7500]\tvalid_set's binary_logloss: 0.0475678\u001b[32m [repeated 17x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=16505)\u001b[0m [7600]\tvalid_set's binary_logloss: 0.047587\u001b[32m [repeated 16x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(_dystack pid=8788)\u001b[0m Saving /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/LightGBMXT_BAG_L1/utils/oof.pkl\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m Saving /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/LightGBMXT_BAG_L1/model.pkl\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m \t0.9698\t = Validation score   (roc_auc)\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m \t461.84s\t = Training   runtime\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m \t230.94s\t = Validation runtime\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m \t284.1\t = Inference  throughput (rows/s | 65616 batch size)\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m Saving /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m Fitting model: LightGBM_BAG_L1 ... Training model for up to 73.25s of the 360.69s of remaining time.\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m \tFitting LightGBM_BAG_L1 with 'num_gpus': 0, 'num_cpus': 96\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m Saving /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/LightGBM_BAG_L1/utils/model_template.pkl\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m Loading: /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/LightGBM_BAG_L1/utils/model_template.pkl\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=12, gpus=0, memory=3.27%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(_ray_fit pid=19462)\u001b[0m [50]\tvalid_set's binary_logloss: 0.0870287\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=19462)\u001b[0m [100]\tvalid_set's binary_logloss: 0.078415\u001b[32m [repeated 10x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=19464)\u001b[0m [150]\tvalid_set's binary_logloss: 0.0745762\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=19463)\u001b[0m [250]\tvalid_set's binary_logloss: 0.0718996\u001b[32m [repeated 11x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=19465)\u001b[0m [250]\tvalid_set's binary_logloss: 0.0711994\u001b[32m [repeated 15x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=19459)\u001b[0m [450]\tvalid_set's binary_logloss: 0.0638379\u001b[32m [repeated 15x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=19466)\u001b[0m [500]\tvalid_set's binary_logloss: 0.0624308\u001b[32m [repeated 13x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=19463)\u001b[0m [600]\tvalid_set's binary_logloss: 0.062946\u001b[32m [repeated 11x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(_dystack pid=8788)\u001b[0m Saving /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/LightGBM_BAG_L1/utils/oof.pkl\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m Saving /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/LightGBM_BAG_L1/model.pkl\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m \t0.9523\t = Validation score   (roc_auc)\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m \t60.66s\t = Training   runtime\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m \t9.71s\t = Validation runtime\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m \t6759.4\t = Inference  throughput (rows/s | 65616 batch size)\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m Saving /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m Fitting model: RandomForestGini_BAG_L1 ... Training model for up to 3.82s of the 291.26s of remaining time.\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m \tFitting RandomForestGini_BAG_L1 with 'num_gpus': 0, 'num_cpus': 96\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m Saving /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/RandomForestGini_BAG_L1/utils/model_template.pkl\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m Loading: /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/RandomForestGini_BAG_L1/utils/model_template.pkl\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m \t139.01s\t= Estimated out-of-fold prediction time...\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m \tNot enough time to generate out-of-fold predictions for model. Estimated time required was 139.01s compared to 10s of available time.\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m \tTime limit exceeded... Skipping RandomForestGini_BAG_L1.\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m Loading: /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/RandomForestGini_BAG_L1/utils/model_template.pkl\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m Saving /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m Skipping RandomForestEntr_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m Saving /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m Skipping CatBoost_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m Saving /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m Skipping ExtraTreesGini_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m Saving /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m Skipping ExtraTreesEntr_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m Saving /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m Skipping NeuralNetFastAI_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m Saving /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m Skipping XGBoost_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m Saving /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m Skipping NeuralNetTorch_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m Saving /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m Skipping LightGBMLarge_BAG_L1 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m Saving /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m Loading: /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/LightGBMXT_BAG_L1/utils/oof.pkl\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m Loading: /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/LightGBM_BAG_L1/utils/oof.pkl\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m Model configs that will be trained (in order):\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m \tWeightedEnsemble_L2: \t{'ag_args': {'valid_base': False, 'name_bag_suffix': '', 'model_type': <class 'autogluon.core.models.greedy_ensemble.greedy_weighted_ensemble_model.GreedyWeightedEnsembleModel'>, 'priority': 0}, 'ag_args_ensemble': {'save_bag_folds': False}}\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m Fitting model: WeightedEnsemble_L2 ... Training model for up to 360.0s of the 255.32s of remaining time.\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m \tFitting WeightedEnsemble_L2 with 'num_gpus': 0, 'num_cpus': 96\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m Saving /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/WeightedEnsemble_L2/utils/model_template.pkl\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m Loading: /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/WeightedEnsemble_L2/utils/model_template.pkl\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m Ensemble size: 1\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m Ensemble weights: \n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m [1. 0.]\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m \t0.66s\t= Estimated out-of-fold prediction time...\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m Saving /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/WeightedEnsemble_L2/utils/oof.pkl\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m Saving /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/WeightedEnsemble_L2/model.pkl\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m \tEnsemble Weights: {'LightGBMXT_BAG_L1': 1.0}\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m \t0.9698\t = Validation score   (roc_auc)\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m \t5.4s\t = Training   runtime\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m \t0.1s\t = Validation runtime\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m \t284.1\t = Inference  throughput (rows/s | 65616 batch size)\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m Saving /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m Excluded models: [] (Specified by `excluded_model_types`)\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m Model configs that will be trained (in order):\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m \tLightGBMXT_BAG_L2: \t{'extra_trees': True, 'ag_args': {'name_suffix': 'XT', 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>, 'priority': 90}, 'ag_args_ensemble': {'save_bag_folds': False}}\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m \tLightGBM_BAG_L2: \t{'ag_args': {'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>, 'priority': 90}, 'ag_args_ensemble': {'save_bag_folds': False}}\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m \tRandomForestGini_BAG_L2: \t{'criterion': 'gini', 'max_depth': 15, 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass'], 'model_type': <class 'autogluon.tabular.models.rf.rf_model.RFModel'>, 'priority': 80}, 'ag_args_ensemble': {'use_child_oof': True, 'save_bag_folds': False}}\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m \tRandomForestEntr_BAG_L2: \t{'criterion': 'entropy', 'max_depth': 15, 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass'], 'model_type': <class 'autogluon.tabular.models.rf.rf_model.RFModel'>, 'priority': 80}, 'ag_args_ensemble': {'use_child_oof': True, 'save_bag_folds': False}}\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m \tCatBoost_BAG_L2: \t{'ag_args': {'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>, 'priority': 70}, 'ag_args_ensemble': {'save_bag_folds': False}}\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m \tExtraTreesGini_BAG_L2: \t{'criterion': 'gini', 'max_depth': 15, 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass'], 'model_type': <class 'autogluon.tabular.models.xt.xt_model.XTModel'>, 'priority': 60}, 'ag_args_ensemble': {'use_child_oof': True, 'save_bag_folds': False}}\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m \tExtraTreesEntr_BAG_L2: \t{'criterion': 'entropy', 'max_depth': 15, 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass'], 'model_type': <class 'autogluon.tabular.models.xt.xt_model.XTModel'>, 'priority': 60}, 'ag_args_ensemble': {'use_child_oof': True, 'save_bag_folds': False}}\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m \tNeuralNetFastAI_BAG_L2: \t{'ag_args': {'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>, 'priority': 50}, 'ag_args_ensemble': {'save_bag_folds': False}}\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m \tXGBoost_BAG_L2: \t{'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'softclass'], 'model_type': <class 'autogluon.tabular.models.xgboost.xgboost_model.XGBoostModel'>, 'priority': 40}, 'ag_args_ensemble': {'save_bag_folds': False}}\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m \tNeuralNetTorch_BAG_L2: \t{'ag_args': {'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>, 'priority': 25}, 'ag_args_ensemble': {'save_bag_folds': False}}\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m \tLightGBMLarge_BAG_L2: \t{'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 5, 'ag_args': {'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>, 'name_suffix': 'Large', 'hyperparameter_tune_kwargs': None, 'priority': 0}, 'ag_args_ensemble': {'save_bag_folds': False}}\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m Fitting 11 L2 models ...\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m Loading: /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/LightGBMXT_BAG_L1/utils/oof.pkl\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m Loading: /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/LightGBM_BAG_L1/utils/oof.pkl\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 249.79s of the 249.11s of remaining time.\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m \tFitting LightGBMXT_BAG_L2 with 'num_gpus': 0, 'num_cpus': 96\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m Saving /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/LightGBMXT_BAG_L2/utils/model_template.pkl\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m Loading: /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/LightGBMXT_BAG_L2/utils/model_template.pkl\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=12, gpus=0, memory=3.30%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(_ray_fit pid=21089)\u001b[0m [50]\tvalid_set's binary_logloss: 0.056042\u001b[32m [repeated 13x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=21093)\u001b[0m [100]\tvalid_set's binary_logloss: 0.0462755\u001b[32m [repeated 10x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=21092)\u001b[0m [150]\tvalid_set's binary_logloss: 0.0472325\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=21086)\u001b[0m [200]\tvalid_set's binary_logloss: 0.0445287\u001b[32m [repeated 13x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=21090)\u001b[0m [300]\tvalid_set's binary_logloss: 0.0438801\u001b[32m [repeated 13x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=21092)\u001b[0m [400]\tvalid_set's binary_logloss: 0.0429908\u001b[32m [repeated 12x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=21088)\u001b[0m [550]\tvalid_set's binary_logloss: 0.041922\u001b[32m [repeated 12x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=21087)\u001b[0m [500]\tvalid_set's binary_logloss: 0.0430395\u001b[32m [repeated 13x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=21091)\u001b[0m [600]\tvalid_set's binary_logloss: 0.0441219\u001b[32m [repeated 15x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=21093)\u001b[0m [750]\tvalid_set's binary_logloss: 0.0415171\u001b[32m [repeated 12x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=21089)\u001b[0m [800]\tvalid_set's binary_logloss: 0.0431524\u001b[32m [repeated 14x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=21087)\u001b[0m [800]\tvalid_set's binary_logloss: 0.043037\u001b[32m [repeated 14x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=21091)\u001b[0m [1000]\tvalid_set's binary_logloss: 0.0440695\u001b[32m [repeated 13x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=21090)\u001b[0m [1150]\tvalid_set's binary_logloss: 0.0422499\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=21086)\u001b[0m [1200]\tvalid_set's binary_logloss: 0.0418311\u001b[32m [repeated 4x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(_dystack pid=8788)\u001b[0m Saving /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/LightGBMXT_BAG_L2/utils/oof.pkl\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m Saving /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/LightGBMXT_BAG_L2/model.pkl\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m \t0.972\t = Validation score   (roc_auc)\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m \t93.49s\t = Training   runtime\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m \t8.2s\t = Validation runtime\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m \t263.7\t = Inference  throughput (rows/s | 65616 batch size)\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m Saving /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m Fitting model: LightGBM_BAG_L2 ... Training model for up to 147.85s of the 147.16s of remaining time.\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m \tFitting LightGBM_BAG_L2 with 'num_gpus': 0, 'num_cpus': 96\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m Saving /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/LightGBM_BAG_L2/utils/model_template.pkl\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m Loading: /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/LightGBM_BAG_L2/utils/model_template.pkl\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=12, gpus=0, memory=3.30%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(_ray_fit pid=22476)\u001b[0m [50]\tvalid_set's binary_logloss: 0.0436994\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=22479)\u001b[0m [100]\tvalid_set's binary_logloss: 0.0433817\u001b[32m [repeated 13x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=22477)\u001b[0m [200]\tvalid_set's binary_logloss: 0.0426208\u001b[32m [repeated 11x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(_dystack pid=8788)\u001b[0m Saving /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/LightGBM_BAG_L2/utils/oof.pkl\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m Saving /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/LightGBM_BAG_L2/model.pkl\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m \t0.9727\t = Validation score   (roc_auc)\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m \t26.97s\t = Training   runtime\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m \t2.6s\t = Validation runtime\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m \t269.7\t = Inference  throughput (rows/s | 65616 batch size)\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m Saving /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m Fitting model: RandomForestGini_BAG_L2 ... Training model for up to 112.99s of the 112.3s of remaining time.\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m \tFitting RandomForestGini_BAG_L2 with 'num_gpus': 0, 'num_cpus': 96\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m Saving /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/RandomForestGini_BAG_L2/utils/model_template.pkl\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m Loading: /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/RandomForestGini_BAG_L2/utils/model_template.pkl\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m \t130.68s\t= Estimated out-of-fold prediction time...\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m \tNot enough time to generate out-of-fold predictions for model. Estimated time required was 130.68s compared to 115.02s of available time.\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m \tTime limit exceeded... Skipping RandomForestGini_BAG_L2.\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m Loading: /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/RandomForestGini_BAG_L2/utils/model_template.pkl\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m Saving /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m Fitting model: RandomForestEntr_BAG_L2 ... Training model for up to 77.79s of the 77.11s of remaining time.\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m \tFitting RandomForestEntr_BAG_L2 with 'num_gpus': 0, 'num_cpus': 96\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m Saving /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/RandomForestEntr_BAG_L2/utils/model_template.pkl\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m Loading: /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/RandomForestEntr_BAG_L2/utils/model_template.pkl\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m \t126.16s\t= Estimated out-of-fold prediction time...\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m \tNot enough time to generate out-of-fold predictions for model. Estimated time required was 126.16s compared to 69.68s of available time.\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m \tTime limit exceeded... Skipping RandomForestEntr_BAG_L2.\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m Loading: /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/RandomForestEntr_BAG_L2/utils/model_template.pkl\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m Saving /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m Fitting model: CatBoost_BAG_L2 ... Training model for up to 43.19s of the 42.5s of remaining time.\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m \tFitting CatBoost_BAG_L2 with 'num_gpus': 0, 'num_cpus': 96\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m Saving /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L2/utils/model_template.pkl\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m Loading: /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L2/utils/model_template.pkl\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=12, gpus=0, memory=3.34%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(_ray_fit pid=24273)\u001b[0m 0:\tlearn: 0.5878536\ttest: 0.5879774\tbest: 0.5879774 (0)\ttotal: 842ms\tremaining: 2h 20m 18s\n",
            "\u001b[36m(_ray_fit pid=22478)\u001b[0m [200]\tvalid_set's binary_logloss: 0.0414538\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=24274)\u001b[0m 20:\tlearn: 0.0650284\ttest: 0.0653728\tbest: 0.0653728 (20)\ttotal: 19.6s\tremaining: 2h 35m 6s\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=24271)\u001b[0m \n",
            "\u001b[36m(_ray_fit pid=24271)\u001b[0m bestTest = 0.05550287062\n",
            "\u001b[36m(_ray_fit pid=24271)\u001b[0m bestIteration = 24\n",
            "\u001b[36m(_ray_fit pid=24271)\u001b[0m \n",
            "\u001b[36m(_ray_fit pid=24271)\u001b[0m Shrink model to first 25 iterations.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(_dystack pid=8788)\u001b[0m Saving /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L2/utils/oof.pkl\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m Saving /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L2/model.pkl\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m \t0.9622\t = Validation score   (roc_auc)\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m \t34.83s\t = Training   runtime\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m \t1.37s\t = Validation runtime\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m \t271.1\t = Inference  throughput (rows/s | 65616 batch size)\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m Saving /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m Skipping ExtraTreesGini_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m Saving /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m Skipping ExtraTreesEntr_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m Saving /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m Skipping NeuralNetFastAI_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m Saving /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m Skipping XGBoost_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m Saving /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m Skipping NeuralNetTorch_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m Saving /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m Skipping LightGBMLarge_BAG_L2 due to lack of time remaining.\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m Saving /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m Loading: /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/LightGBMXT_BAG_L1/utils/oof.pkl\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m Loading: /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/LightGBM_BAG_L1/utils/oof.pkl\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m Loading: /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/LightGBMXT_BAG_L2/utils/oof.pkl\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m Loading: /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/LightGBM_BAG_L2/utils/oof.pkl\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m Loading: /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L2/utils/oof.pkl\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m Model configs that will be trained (in order):\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m \tWeightedEnsemble_L3: \t{'ag_args': {'valid_base': False, 'name_bag_suffix': '', 'model_type': <class 'autogluon.core.models.greedy_ensemble.greedy_weighted_ensemble_model.GreedyWeightedEnsembleModel'>, 'priority': 0}, 'ag_args_ensemble': {'save_bag_folds': False}}\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m Fitting model: WeightedEnsemble_L3 ... Training model for up to 360.0s of the -0.17s of remaining time.\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m \tFitting WeightedEnsemble_L3 with 'num_gpus': 0, 'num_cpus': 96\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m Saving /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/WeightedEnsemble_L3/utils/model_template.pkl\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m Loading: /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/WeightedEnsemble_L3/utils/model_template.pkl\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m Ensemble size: 22\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m Ensemble weights: \n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m [0.         0.         0.31818182 0.63636364 0.04545455]\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m \t1.58s\t= Estimated out-of-fold prediction time...\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m Saving /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/WeightedEnsemble_L3/utils/oof.pkl\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m Saving /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/WeightedEnsemble_L3/model.pkl\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m \tEnsemble Weights: {'LightGBM_BAG_L2': 0.636, 'LightGBMXT_BAG_L2': 0.318, 'CatBoost_BAG_L2': 0.045}\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m \t0.973\t = Validation score   (roc_auc)\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m \t13.08s\t = Training   runtime\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m \t0.09s\t = Validation runtime\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m \t259.5\t = Inference  throughput (rows/s | 65616 batch size)\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m Saving /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m Saving /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m Saving /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m AutoGluon training complete, total runtime = 911.44s ... Best model: WeightedEnsemble_L3 | Estimated inference throughput: 259.5 rows/s (65616 batch size)\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m Loading: /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m Automatically performing refit_full as a post-fit operation (due to `.fit(..., refit_full=True)`\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m Refitting models via `predictor.refit_full` using all of the data (combined train and validation)...\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m \tModels trained in this way will have the suffix \"_FULL\" and have NaN validation score.\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m \tThis process is not bound by time_limit, but should take less time than the original `predictor.fit` call.\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m \tTo learn more, refer to the `.refit_full` method docstring which explains how \"_FULL\" models differ from normal models.\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m Loading: /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/utils/data/X.pkl\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m Loading: /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/utils/data/y.pkl\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m Loading: /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/LightGBMXT_BAG_L1/model.pkl\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m Loading: /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/LightGBMXT_BAG_L1/utils/model_template.pkl\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m Loading: /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/LightGBMXT_BAG_L1/utils/model_template.pkl\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m Loading: /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/LightGBMXT_BAG_L1/utils/model_template.pkl\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m Fitting 1 L1 models ...\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m Fitting model: LightGBMXT_BAG_L1_FULL ...\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m \tFitting LightGBMXT_BAG_L1_FULL with 'num_gpus': 0, 'num_cpus': 48\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m Saving /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/LightGBMXT_BAG_L1_FULL/utils/model_template.pkl\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m Loading: /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/LightGBMXT_BAG_L1_FULL/utils/model_template.pkl\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m \tFitting 7212 rounds... Hyperparameters: {'learning_rate': 0.05, 'extra_trees': True}\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m Saving /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/LightGBMXT_BAG_L1_FULL/model.pkl\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m \t174.95s\t = Training   runtime\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m Saving /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m Loading: /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/LightGBM_BAG_L1/model.pkl\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m Loading: /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/LightGBM_BAG_L1/utils/model_template.pkl\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m Loading: /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/LightGBM_BAG_L1/utils/model_template.pkl\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m Loading: /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/LightGBM_BAG_L1/utils/model_template.pkl\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m Fitting 1 L1 models ...\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m Fitting model: LightGBM_BAG_L1_FULL ...\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m \tFitting LightGBM_BAG_L1_FULL with 'num_gpus': 0, 'num_cpus': 48\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m Saving /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/LightGBM_BAG_L1_FULL/utils/model_template.pkl\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m Loading: /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/LightGBM_BAG_L1_FULL/utils/model_template.pkl\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m \tFitting 633 rounds... Hyperparameters: {'learning_rate': 0.05}\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m Saving /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/LightGBM_BAG_L1_FULL/model.pkl\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m \t25.62s\t = Training   runtime\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m Saving /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m Loading: /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/WeightedEnsemble_L2/model.pkl\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m Fitting model: WeightedEnsemble_L2_FULL | Skipping fit via cloning parent ...\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m \tEnsemble Weights: {'LightGBMXT_BAG_L1': 1.0}\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m \t5.4s\t = Training   runtime\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m Saving /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/WeightedEnsemble_L2_FULL/model.pkl\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m Loading: /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/LightGBMXT_BAG_L2/model.pkl\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m Loading: /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/LightGBMXT_BAG_L2/utils/model_template.pkl\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m Loading: /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/LightGBMXT_BAG_L2/utils/model_template.pkl\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m Loading: /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/LightGBMXT_BAG_L2/utils/model_template.pkl\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m Fitting 1 L2 models ...\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m Loading: /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/LightGBMXT_BAG_L1/utils/oof.pkl\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m Loading: /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/LightGBM_BAG_L1/utils/oof.pkl\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m Fitting model: LightGBMXT_BAG_L2_FULL ...\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m \tFitting LightGBMXT_BAG_L2_FULL with 'num_gpus': 0, 'num_cpus': 48\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m Saving /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/LightGBMXT_BAG_L2_FULL/utils/model_template.pkl\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m Loading: /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/LightGBMXT_BAG_L2_FULL/utils/model_template.pkl\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m \tFitting 799 rounds... Hyperparameters: {'learning_rate': 0.05, 'extra_trees': True}\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m Saving /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/LightGBMXT_BAG_L2_FULL/model.pkl\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m \t28.82s\t = Training   runtime\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m Saving /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m Loading: /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/LightGBM_BAG_L2/model.pkl\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m Loading: /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/LightGBM_BAG_L2/utils/model_template.pkl\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m Loading: /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/LightGBM_BAG_L2/utils/model_template.pkl\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m Loading: /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/LightGBM_BAG_L2/utils/model_template.pkl\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m Fitting 1 L2 models ...\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m Loading: /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/LightGBMXT_BAG_L1/utils/oof.pkl\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m Loading: /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/LightGBM_BAG_L1/utils/oof.pkl\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m Fitting model: LightGBM_BAG_L2_FULL ...\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m \tFitting LightGBM_BAG_L2_FULL with 'num_gpus': 0, 'num_cpus': 48\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m Saving /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/LightGBM_BAG_L2_FULL/utils/model_template.pkl\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m Loading: /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/LightGBM_BAG_L2_FULL/utils/model_template.pkl\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m \tFitting 141 rounds... Hyperparameters: {'learning_rate': 0.05}\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m Saving /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/LightGBM_BAG_L2_FULL/model.pkl\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m \t12.59s\t = Training   runtime\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m Saving /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m Loading: /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L2/model.pkl\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m Loading: /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L2/utils/model_template.pkl\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m Loading: /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L2/utils/model_template.pkl\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m Loading: /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L2/utils/model_template.pkl\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m Fitting 1 L2 models ...\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m Loading: /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/LightGBMXT_BAG_L1/utils/oof.pkl\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m Loading: /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/LightGBM_BAG_L1/utils/oof.pkl\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m Fitting model: CatBoost_BAG_L2_FULL ...\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m \tFitting CatBoost_BAG_L2_FULL with 'num_gpus': 0, 'num_cpus': 48\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m Saving /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L2_FULL/utils/model_template.pkl\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m Loading: /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L2_FULL/utils/model_template.pkl\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m \tCatboost model hyperparameters: {'iterations': 25, 'learning_rate': 0.05, 'random_seed': 0, 'allow_writing_files': False, 'eval_metric': 'Logloss', 'thread_count': 48}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(_dystack pid=8788)\u001b[0m 0:\tlearn: 0.5852337\ttotal: 205ms\tremaining: 4.92s\n",
            "\u001b[36m(_ray_fit pid=24273)\u001b[0m 20:\tlearn: 0.0646370\ttest: 0.0654382\tbest: 0.0654382 (20)\ttotal: 21.5s\tremaining: 2h 50m 31s\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=24272)\u001b[0m \u001b[32m [repeated 14x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=24272)\u001b[0m bestTest = 0.05497604913\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=24272)\u001b[0m bestIteration = 24\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=24272)\u001b[0m Shrink model to first 25 iterations.\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m 20:\tlearn: 0.0637626\ttotal: 1.92s\tremaining: 366ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(_dystack pid=8788)\u001b[0m Saving /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L2_FULL/model.pkl\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m \t6.51s\t = Training   runtime\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m Saving /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m Loading: /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/WeightedEnsemble_L3/model.pkl\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m Fitting model: WeightedEnsemble_L3_FULL | Skipping fit via cloning parent ...\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m \tEnsemble Weights: {'LightGBM_BAG_L2': 0.636, 'LightGBMXT_BAG_L2': 0.318, 'CatBoost_BAG_L2': 0.045}\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m \t13.08s\t = Training   runtime\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m Saving /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/WeightedEnsemble_L3_FULL/model.pkl\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m Saving /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m Loading: /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/LightGBMXT_BAG_L1_FULL/model.pkl\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m Saving /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/LightGBMXT_BAG_L1_FULL/model.pkl\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m Loading: /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/LightGBM_BAG_L1_FULL/model.pkl\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m Saving /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/LightGBM_BAG_L1_FULL/model.pkl\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m Loading: /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/WeightedEnsemble_L2_FULL/model.pkl\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m Saving /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/WeightedEnsemble_L2_FULL/model.pkl\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m Loading: /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/LightGBMXT_BAG_L2_FULL/model.pkl\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m Saving /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/LightGBMXT_BAG_L2_FULL/model.pkl\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m Loading: /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/LightGBM_BAG_L2_FULL/model.pkl\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m Saving /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/LightGBM_BAG_L2_FULL/model.pkl\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m Loading: /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L2_FULL/model.pkl\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m Saving /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L2_FULL/model.pkl\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m Loading: /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/WeightedEnsemble_L3_FULL/model.pkl\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m Saving /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/WeightedEnsemble_L3_FULL/model.pkl\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m Saving /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m Saving /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m Updated best model to \"WeightedEnsemble_L3_FULL\" (Previously \"WeightedEnsemble_L3\"). AutoGluon will default to using \"WeightedEnsemble_L3_FULL\" for predict() and predict_proba().\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m Refit complete, total runtime = 265.32s ... Best model: \"WeightedEnsemble_L3_FULL\"\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m Saving /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m Saving /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/learner.pkl\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m Saving /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/predictor.pkl\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m Saving /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/version.txt with contents \"1.1.1\"\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m Saving /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/metadata.json\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/content/AutoGluonModels/ds_sub_fit/sub_fit_ho\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(_dystack pid=8788)\u001b[0m 24:\tlearn: 0.0556805\ttotal: 2.26s\tremaining: 0us\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(_dystack pid=8788)\u001b[0m Loading: /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/LightGBMXT_BAG_L1_FULL/model.pkl\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m Loading: /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/LightGBM_BAG_L1_FULL/model.pkl\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m Loading: /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/WeightedEnsemble_L2_FULL/model.pkl\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m Loading: /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/LightGBMXT_BAG_L2_FULL/model.pkl\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m Loading: /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/LightGBM_BAG_L2_FULL/model.pkl\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m Loading: /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L2_FULL/model.pkl\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m Loading: /content/AutoGluonModels/ds_sub_fit/sub_fit_ho/models/WeightedEnsemble_L3_FULL/model.pkl\n",
            "\u001b[36m(_dystack pid=8788)\u001b[0m Deleting DyStack predictor artifacts (clean_up_fits=True) ...\n",
            "Leaderboard on holdout data (DyStack):\n",
            "                      model  score_holdout  score_val eval_metric  pred_time_test pred_time_val    fit_time  pred_time_test_marginal pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
            "0    LightGBMXT_BAG_L2_FULL       0.977323   0.971980     roc_auc        2.685785          None  229.397439                 0.466792                   None          28.819955            2       True          4\n",
            "1  WeightedEnsemble_L3_FULL       0.976565   0.972996     roc_auc        3.166059          None  261.575013                 0.003850                   None          13.075303            3       True          7\n",
            "2      LightGBM_BAG_L2_FULL       0.975684   0.972656     roc_auc        2.504399          None  213.166059                 0.285405                   None          12.588574            2       True          5\n",
            "3    LightGBMXT_BAG_L1_FULL       0.973497   0.969773     roc_auc        1.842900          None  174.953490                 1.842900                   None         174.953490            1       True          1\n",
            "4  WeightedEnsemble_L2_FULL       0.973497   0.969773     roc_auc        1.845542          None  180.354410                 0.002642                   None           5.400920            2       True          3\n",
            "5      CatBoost_BAG_L2_FULL       0.968448   0.962160     roc_auc        2.410012          None  207.091180                 0.191018                   None           6.513696            2       True          6\n",
            "6      LightGBM_BAG_L1_FULL       0.951086   0.952327     roc_auc        0.376093          None   25.623994                 0.376093                   None          25.623994            1       True          2\n",
            "\t1\t = Optimal   num_stack_levels (Stacked Overfitting Occurred: False)\n",
            "\t1195s\t = DyStack   runtime |\t2405s\t = Remaining runtime\n",
            "Starting main fit with num_stack_levels=1.\n",
            "\tFor future fit calls on this dataset, you can skip DyStack to save time: `predictor.fit(..., dynamic_stacking=False, num_stack_levels=1)`\n",
            "Saving /content/AutoGluonModels/learner.pkl\n",
            "Saving /content/AutoGluonModels/predictor.pkl\n",
            "Beginning AutoGluon training ... Time limit = 2405s\n",
            "AutoGluon will save models to \"/content/AutoGluonModels/\"\n",
            "Train Data Rows:    590540\n",
            "Train Data Columns: 433\n",
            "Label Column:       isFraud\n",
            "Problem Type:       binary\n",
            "Preprocessing data ...\n",
            "Selected class <--> label mapping:  class 1 = 1, class 0 = 0\n",
            "Using Feature Generators to preprocess the data ...\n",
            "Fitting AutoMLPipelineFeatureGenerator...\n",
            "\tAvailable Memory:                    328145.80 MB\n",
            "\tTrain Data (Original)  Memory Usage: 2590.15 MB (0.8% of available memory)\n",
            "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
            "\tStage 1 Generators:\n",
            "\t\tFitting AsTypeFeatureGenerator...\n",
            "\t\t\tOriginal Features (exact raw dtype, raw dtype):\n",
            "\t\t\t\t('float64', 'float') : 399 | ['TransactionAmt', 'card2', 'card3', 'card5', 'addr1', ...]\n",
            "\t\t\t\t('int64', 'int')     :   3 | ['TransactionID', 'TransactionDT', 'card1']\n",
            "\t\t\t\t('object', 'object') :  31 | ['ProductCD', 'card4', 'card6', 'P_emaildomain', 'R_emaildomain', ...]\n",
            "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t\t\t('float', [])  : 399 | ['TransactionAmt', 'card2', 'card3', 'card5', 'addr1', ...]\n",
            "\t\t\t\t('int', [])    :   3 | ['TransactionID', 'TransactionDT', 'card1']\n",
            "\t\t\t\t('object', []) :  31 | ['ProductCD', 'card4', 'card6', 'P_emaildomain', 'R_emaildomain', ...]\n",
            "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t\t\t('float', [])  : 399 | ['TransactionAmt', 'card2', 'card3', 'card5', 'addr1', ...]\n",
            "\t\t\t\t('int', [])    :   3 | ['TransactionID', 'TransactionDT', 'card1']\n",
            "\t\t\t\t('object', []) :  31 | ['ProductCD', 'card4', 'card6', 'P_emaildomain', 'R_emaildomain', ...]\n",
            "\t\t\t4.0s = Fit runtime\n",
            "\t\t\t433 features in original data used to generate 433 features in processed data.\n",
            "\tStage 2 Generators:\n",
            "\t\tFitting FillNaFeatureGenerator...\n",
            "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t\t\t('float', [])  : 399 | ['TransactionAmt', 'card2', 'card3', 'card5', 'addr1', ...]\n",
            "\t\t\t\t('int', [])    :   3 | ['TransactionID', 'TransactionDT', 'card1']\n",
            "\t\t\t\t('object', []) :  31 | ['ProductCD', 'card4', 'card6', 'P_emaildomain', 'R_emaildomain', ...]\n",
            "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t\t\t('float', [])  : 399 | ['TransactionAmt', 'card2', 'card3', 'card5', 'addr1', ...]\n",
            "\t\t\t\t('int', [])    :   3 | ['TransactionID', 'TransactionDT', 'card1']\n",
            "\t\t\t\t('object', []) :  31 | ['ProductCD', 'card4', 'card6', 'P_emaildomain', 'R_emaildomain', ...]\n",
            "\t\t\t1.8s = Fit runtime\n",
            "\t\t\t433 features in original data used to generate 433 features in processed data.\n",
            "\tStage 3 Generators:\n",
            "\t\tFitting IdentityFeatureGenerator...\n",
            "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t\t\t('float', []) : 399 | ['TransactionAmt', 'card2', 'card3', 'card5', 'addr1', ...]\n",
            "\t\t\t\t('int', [])   :   3 | ['TransactionID', 'TransactionDT', 'card1']\n",
            "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t\t\t('float', []) : 399 | ['TransactionAmt', 'card2', 'card3', 'card5', 'addr1', ...]\n",
            "\t\t\t\t('int', [])   :   3 | ['TransactionID', 'TransactionDT', 'card1']\n",
            "\t\t\t0.9s = Fit runtime\n",
            "\t\t\t402 features in original data used to generate 402 features in processed data.\n",
            "\t\tFitting CategoryFeatureGenerator...\n",
            "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
            "\t\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t\t\t\t('category', []) : 31 | ['ProductCD', 'card4', 'card6', 'P_emaildomain', 'R_emaildomain', ...]\n",
            "\t\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t\t\t\t('category', []) : 31 | ['ProductCD', 'card4', 'card6', 'P_emaildomain', 'R_emaildomain', ...]\n",
            "\t\t\t\t0.3s = Fit runtime\n",
            "\t\t\t\t31 features in original data used to generate 31 features in processed data.\n",
            "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t\t\t('object', []) : 31 | ['ProductCD', 'card4', 'card6', 'P_emaildomain', 'R_emaildomain', ...]\n",
            "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t\t\t('category', []) : 31 | ['ProductCD', 'card4', 'card6', 'P_emaildomain', 'R_emaildomain', ...]\n",
            "\t\t\t1.4s = Fit runtime\n",
            "\t\t\t31 features in original data used to generate 31 features in processed data.\n",
            "\t\tSkipping DatetimeFeatureGenerator: No input feature with required dtypes.\n",
            "\t\tSkipping TextSpecialFeatureGenerator: No input feature with required dtypes.\n",
            "\t\tSkipping TextNgramFeatureGenerator: No input feature with required dtypes.\n",
            "\t\tSkipping IdentityFeatureGenerator: No input feature with required dtypes.\n",
            "\t\tSkipping IsNanFeatureGenerator: No input feature with required dtypes.\n",
            "\tStage 4 Generators:\n",
            "\t\tFitting DropUniqueFeatureGenerator...\n",
            "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t\t\t('category', []) :  31 | ['ProductCD', 'card4', 'card6', 'P_emaildomain', 'R_emaildomain', ...]\n",
            "\t\t\t\t('float', [])    : 399 | ['TransactionAmt', 'card2', 'card3', 'card5', 'addr1', ...]\n",
            "\t\t\t\t('int', [])      :   3 | ['TransactionID', 'TransactionDT', 'card1']\n",
            "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t\t\t('category', []) :  31 | ['ProductCD', 'card4', 'card6', 'P_emaildomain', 'R_emaildomain', ...]\n",
            "\t\t\t\t('float', [])    : 399 | ['TransactionAmt', 'card2', 'card3', 'card5', 'addr1', ...]\n",
            "\t\t\t\t('int', [])      :   3 | ['TransactionID', 'TransactionDT', 'card1']\n",
            "\t\t\t3.8s = Fit runtime\n",
            "\t\t\t433 features in original data used to generate 433 features in processed data.\n",
            "\tStage 5 Generators:\n",
            "\t\tFitting DropDuplicatesFeatureGenerator...\n",
            "\t\t\t5 duplicate columns removed: ['V28', 'V113', 'V119', 'V122', 'V154']\n",
            "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t\t\t('category', []) :  31 | ['ProductCD', 'card4', 'card6', 'P_emaildomain', 'R_emaildomain', ...]\n",
            "\t\t\t\t('float', [])    : 394 | ['TransactionAmt', 'card2', 'card3', 'card5', 'addr1', ...]\n",
            "\t\t\t\t('int', [])      :   3 | ['TransactionID', 'TransactionDT', 'card1']\n",
            "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t\t\t('category', []) :  31 | ['ProductCD', 'card4', 'card6', 'P_emaildomain', 'R_emaildomain', ...]\n",
            "\t\t\t\t('float', [])    : 394 | ['TransactionAmt', 'card2', 'card3', 'card5', 'addr1', ...]\n",
            "\t\t\t\t('int', [])      :   3 | ['TransactionID', 'TransactionDT', 'card1']\n",
            "\t\t\t4.7s = Fit runtime\n",
            "\t\t\t428 features in original data used to generate 428 features in processed data.\n",
            "\tUnused Original Features (Count: 5): ['V28', 'V113', 'V119', 'V122', 'V154']\n",
            "\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
            "\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
            "\t\tThese features do not need to be present at inference time.\n",
            "\t\t('float', []) : 5 | ['V28', 'V113', 'V119', 'V122', 'V154']\n",
            "\tTypes of features in original data (exact raw dtype, raw dtype):\n",
            "\t\t('float64', 'float') : 394 | ['TransactionAmt', 'card2', 'card3', 'card5', 'addr1', ...]\n",
            "\t\t('int64', 'int')     :   3 | ['TransactionID', 'TransactionDT', 'card1']\n",
            "\t\t('object', 'object') :  31 | ['ProductCD', 'card4', 'card6', 'P_emaildomain', 'R_emaildomain', ...]\n",
            "\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t('float', [])  : 394 | ['TransactionAmt', 'card2', 'card3', 'card5', 'addr1', ...]\n",
            "\t\t('int', [])    :   3 | ['TransactionID', 'TransactionDT', 'card1']\n",
            "\t\t('object', []) :  31 | ['ProductCD', 'card4', 'card6', 'P_emaildomain', 'R_emaildomain', ...]\n",
            "\tTypes of features in processed data (exact raw dtype, raw dtype):\n",
            "\t\t('category', 'category') :  31 | ['ProductCD', 'card4', 'card6', 'P_emaildomain', 'R_emaildomain', ...]\n",
            "\t\t('float64', 'float')     : 394 | ['TransactionAmt', 'card2', 'card3', 'card5', 'addr1', ...]\n",
            "\t\t('int64', 'int')         :   3 | ['TransactionID', 'TransactionDT', 'card1']\n",
            "\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t('category', []) :  31 | ['ProductCD', 'card4', 'card6', 'P_emaildomain', 'R_emaildomain', ...]\n",
            "\t\t('float', [])    : 394 | ['TransactionAmt', 'card2', 'card3', 'card5', 'addr1', ...]\n",
            "\t\t('int', [])      :   3 | ['TransactionID', 'TransactionDT', 'card1']\n",
            "\t24.3s = Fit runtime\n",
            "\t428 features in original data used to generate 428 features in processed data.\n",
            "\tTrain Data (Processed) Memory Usage: 1807.27 MB (0.6% of available memory)\n",
            "Data preprocessing and feature engineering runtime = 28.95s ...\n",
            "AutoGluon will gauge predictive performance using evaluation metric: 'roc_auc'\n",
            "\tThis metric expects predicted probabilities rather than predicted class labels, so you'll need to use predict_proba() instead of predict()\n",
            "\tTo change this, specify the eval_metric parameter of Predictor()\n",
            "Saving /content/AutoGluonModels/learner.pkl\n",
            "User-specified model hyperparameters to be fit:\n",
            "{\n",
            "\t'NN_TORCH': {},\n",
            "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
            "\t'CAT': {},\n",
            "\t'XGB': {},\n",
            "\t'FASTAI': {},\n",
            "\t'RF': [{'criterion': 'gini', 'max_depth': 15, 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'max_depth': 15, 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'max_depth': 15, 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
            "\t'XT': [{'criterion': 'gini', 'max_depth': 15, 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'max_depth': 15, 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'max_depth': 15, 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
            "}\n",
            "Saving /content/AutoGluonModels/utils/data/X.pkl\n",
            "Saving /content/AutoGluonModels/utils/data/y.pkl\n",
            "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
            "Excluded models: [] (Specified by `excluded_model_types`)\n",
            "Model configs that will be trained (in order):\n",
            "\tLightGBMXT_BAG_L1: \t{'extra_trees': True, 'ag_args': {'name_suffix': 'XT', 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>, 'priority': 90}, 'ag_args_ensemble': {'save_bag_folds': False}}\n",
            "\tLightGBM_BAG_L1: \t{'ag_args': {'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>, 'priority': 90}, 'ag_args_ensemble': {'save_bag_folds': False}}\n",
            "\tRandomForestGini_BAG_L1: \t{'criterion': 'gini', 'max_depth': 15, 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass'], 'model_type': <class 'autogluon.tabular.models.rf.rf_model.RFModel'>, 'priority': 80}, 'ag_args_ensemble': {'use_child_oof': True, 'save_bag_folds': False}}\n",
            "\tRandomForestEntr_BAG_L1: \t{'criterion': 'entropy', 'max_depth': 15, 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass'], 'model_type': <class 'autogluon.tabular.models.rf.rf_model.RFModel'>, 'priority': 80}, 'ag_args_ensemble': {'use_child_oof': True, 'save_bag_folds': False}}\n",
            "\tCatBoost_BAG_L1: \t{'ag_args': {'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>, 'priority': 70}, 'ag_args_ensemble': {'save_bag_folds': False}}\n",
            "\tExtraTreesGini_BAG_L1: \t{'criterion': 'gini', 'max_depth': 15, 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass'], 'model_type': <class 'autogluon.tabular.models.xt.xt_model.XTModel'>, 'priority': 60}, 'ag_args_ensemble': {'use_child_oof': True, 'save_bag_folds': False}}\n",
            "\tExtraTreesEntr_BAG_L1: \t{'criterion': 'entropy', 'max_depth': 15, 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass'], 'model_type': <class 'autogluon.tabular.models.xt.xt_model.XTModel'>, 'priority': 60}, 'ag_args_ensemble': {'use_child_oof': True, 'save_bag_folds': False}}\n",
            "\tNeuralNetFastAI_BAG_L1: \t{'ag_args': {'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>, 'priority': 50}, 'ag_args_ensemble': {'save_bag_folds': False}}\n",
            "\tXGBoost_BAG_L1: \t{'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'softclass'], 'model_type': <class 'autogluon.tabular.models.xgboost.xgboost_model.XGBoostModel'>, 'priority': 40}, 'ag_args_ensemble': {'save_bag_folds': False}}\n",
            "\tNeuralNetTorch_BAG_L1: \t{'ag_args': {'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>, 'priority': 25}, 'ag_args_ensemble': {'save_bag_folds': False}}\n",
            "\tLightGBMLarge_BAG_L1: \t{'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 5, 'ag_args': {'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>, 'name_suffix': 'Large', 'hyperparameter_tune_kwargs': None, 'priority': 0}, 'ag_args_ensemble': {'save_bag_folds': False}}\n",
            "Fitting 11 L1 models ...\n",
            "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 1583.54s of the 2375.89s of remaining time.\n",
            "\tFitting LightGBMXT_BAG_L1 with 'num_gpus': 0, 'num_cpus': 96\n",
            "Saving /content/AutoGluonModels/models/LightGBMXT_BAG_L1/utils/model_template.pkl\n",
            "Loading: /content/AutoGluonModels/models/LightGBMXT_BAG_L1/utils/model_template.pkl\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=12, gpus=0, memory=3.63%)\n",
            "Saving /content/AutoGluonModels/models/LightGBMXT_BAG_L1/utils/oof.pkl\n",
            "Saving /content/AutoGluonModels/models/LightGBMXT_BAG_L1/model.pkl\n",
            "\t0.9718\t = Validation score   (roc_auc)\n",
            "\t677.77s\t = Training   runtime\n",
            "\t140.29s\t = Validation runtime\n",
            "\t526.2\t = Inference  throughput (rows/s | 73818 batch size)\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Fitting model: LightGBM_BAG_L1 ... Training model for up to 883.08s of the 1675.43s of remaining time.\n",
            "\tFitting LightGBM_BAG_L1 with 'num_gpus': 0, 'num_cpus': 96\n",
            "Saving /content/AutoGluonModels/models/LightGBM_BAG_L1/utils/model_template.pkl\n",
            "Loading: /content/AutoGluonModels/models/LightGBM_BAG_L1/utils/model_template.pkl\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=12, gpus=0, memory=3.63%)\n",
            "Saving /content/AutoGluonModels/models/LightGBM_BAG_L1/utils/oof.pkl\n",
            "Saving /content/AutoGluonModels/models/LightGBM_BAG_L1/model.pkl\n",
            "\t0.9743\t = Validation score   (roc_auc)\n",
            "\t520.99s\t = Training   runtime\n",
            "\t56.49s\t = Validation runtime\n",
            "\t1306.7\t = Inference  throughput (rows/s | 73818 batch size)\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Fitting model: RandomForestGini_BAG_L1 ... Training model for up to 349.3s of the 1141.65s of remaining time.\n",
            "\tFitting RandomForestGini_BAG_L1 with 'num_gpus': 0, 'num_cpus': 96\n",
            "Saving /content/AutoGluonModels/models/RandomForestGini_BAG_L1/utils/model_template.pkl\n",
            "Loading: /content/AutoGluonModels/models/RandomForestGini_BAG_L1/utils/model_template.pkl\n",
            "\t141.88s\t= Estimated out-of-fold prediction time...\n",
            "\t`use_child_oof` was specified for this model. It will function similarly to a bagged model, but will only fit one child model.\n",
            "Saving /content/AutoGluonModels/models/RandomForestGini_BAG_L1/utils/oof.pkl\n",
            "Saving /content/AutoGluonModels/models/RandomForestGini_BAG_L1/model.pkl\n",
            "\t0.8933\t = Validation score   (roc_auc)\n",
            "\t37.55s\t = Training   runtime\n",
            "\t125.71s\t = Validation runtime\n",
            "\t4697.6\t = Inference  throughput (rows/s | 590540 batch size)\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Fitting model: RandomForestEntr_BAG_L1 ... Training model for up to 182.52s of the 974.87s of remaining time.\n",
            "\tFitting RandomForestEntr_BAG_L1 with 'num_gpus': 0, 'num_cpus': 96\n",
            "Saving /content/AutoGluonModels/models/RandomForestEntr_BAG_L1/utils/model_template.pkl\n",
            "Loading: /content/AutoGluonModels/models/RandomForestEntr_BAG_L1/utils/model_template.pkl\n",
            "\t153.34s\t= Estimated out-of-fold prediction time...\n",
            "\t`use_child_oof` was specified for this model. It will function similarly to a bagged model, but will only fit one child model.\n",
            "Saving /content/AutoGluonModels/models/RandomForestEntr_BAG_L1/utils/oof.pkl\n",
            "Saving /content/AutoGluonModels/models/RandomForestEntr_BAG_L1/model.pkl\n",
            "\t0.9142\t = Validation score   (roc_auc)\n",
            "\t33.07s\t = Training   runtime\n",
            "\t127.03s\t = Validation runtime\n",
            "\t4648.7\t = Inference  throughput (rows/s | 590540 batch size)\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Fitting model: CatBoost_BAG_L1 ... Training model for up to 18.99s of the 811.34s of remaining time.\n",
            "\tFitting CatBoost_BAG_L1 with 'num_gpus': 0, 'num_cpus': 96\n",
            "Saving /content/AutoGluonModels/models/CatBoost_BAG_L1/utils/model_template.pkl\n",
            "Loading: /content/AutoGluonModels/models/CatBoost_BAG_L1/utils/model_template.pkl\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=12, gpus=0, memory=3.71%)\n",
            "Saving /content/AutoGluonModels/models/CatBoost_BAG_L1/utils/oof.pkl\n",
            "Saving /content/AutoGluonModels/models/CatBoost_BAG_L1/model.pkl\n",
            "\t0.7631\t = Validation score   (roc_auc)\n",
            "\t15.15s\t = Training   runtime\n",
            "\t1.48s\t = Validation runtime\n",
            "\t49844.6\t = Inference  throughput (rows/s | 73818 batch size)\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Skipping ExtraTreesGini_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Skipping ExtraTreesEntr_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetFastAI_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Skipping XGBoost_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetTorch_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Skipping LightGBMLarge_BAG_L1 due to lack of time remaining.\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Loading: /content/AutoGluonModels/models/LightGBMXT_BAG_L1/utils/oof.pkl\n",
            "Loading: /content/AutoGluonModels/models/LightGBM_BAG_L1/utils/oof.pkl\n",
            "Loading: /content/AutoGluonModels/models/RandomForestGini_BAG_L1/utils/oof.pkl\n",
            "Loading: /content/AutoGluonModels/models/RandomForestEntr_BAG_L1/utils/oof.pkl\n",
            "Loading: /content/AutoGluonModels/models/CatBoost_BAG_L1/utils/oof.pkl\n",
            "Model configs that will be trained (in order):\n",
            "\tWeightedEnsemble_L2: \t{'ag_args': {'valid_base': False, 'name_bag_suffix': '', 'model_type': <class 'autogluon.core.models.greedy_ensemble.greedy_weighted_ensemble_model.GreedyWeightedEnsembleModel'>, 'priority': 0}, 'ag_args_ensemble': {'save_bag_folds': False}}\n",
            "Fitting model: WeightedEnsemble_L2 ... Training model for up to 360.0s of the 788.04s of remaining time.\n",
            "\tFitting WeightedEnsemble_L2 with 'num_gpus': 0, 'num_cpus': 96\n",
            "Saving /content/AutoGluonModels/models/WeightedEnsemble_L2/utils/model_template.pkl\n",
            "Loading: /content/AutoGluonModels/models/WeightedEnsemble_L2/utils/model_template.pkl\n",
            "Ensemble size: 4\n",
            "Ensemble weights: \n",
            "[0.25 0.75 0.   0.   0.  ]\n",
            "\t1.43s\t= Estimated out-of-fold prediction time...\n",
            "Saving /content/AutoGluonModels/models/WeightedEnsemble_L2/utils/oof.pkl\n",
            "Saving /content/AutoGluonModels/models/WeightedEnsemble_L2/model.pkl\n",
            "\tEnsemble Weights: {'LightGBM_BAG_L1': 0.75, 'LightGBMXT_BAG_L1': 0.25}\n",
            "\t0.975\t = Validation score   (roc_auc)\n",
            "\t14.24s\t = Training   runtime\n",
            "\t0.11s\t = Validation runtime\n",
            "\t375.1\t = Inference  throughput (rows/s | 73818 batch size)\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Excluded models: [] (Specified by `excluded_model_types`)\n",
            "Model configs that will be trained (in order):\n",
            "\tLightGBMXT_BAG_L2: \t{'extra_trees': True, 'ag_args': {'name_suffix': 'XT', 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>, 'priority': 90}, 'ag_args_ensemble': {'save_bag_folds': False}}\n",
            "\tLightGBM_BAG_L2: \t{'ag_args': {'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>, 'priority': 90}, 'ag_args_ensemble': {'save_bag_folds': False}}\n",
            "\tRandomForestGini_BAG_L2: \t{'criterion': 'gini', 'max_depth': 15, 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass'], 'model_type': <class 'autogluon.tabular.models.rf.rf_model.RFModel'>, 'priority': 80}, 'ag_args_ensemble': {'use_child_oof': True, 'save_bag_folds': False}}\n",
            "\tRandomForestEntr_BAG_L2: \t{'criterion': 'entropy', 'max_depth': 15, 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass'], 'model_type': <class 'autogluon.tabular.models.rf.rf_model.RFModel'>, 'priority': 80}, 'ag_args_ensemble': {'use_child_oof': True, 'save_bag_folds': False}}\n",
            "\tCatBoost_BAG_L2: \t{'ag_args': {'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>, 'priority': 70}, 'ag_args_ensemble': {'save_bag_folds': False}}\n",
            "\tExtraTreesGini_BAG_L2: \t{'criterion': 'gini', 'max_depth': 15, 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass'], 'model_type': <class 'autogluon.tabular.models.xt.xt_model.XTModel'>, 'priority': 60}, 'ag_args_ensemble': {'use_child_oof': True, 'save_bag_folds': False}}\n",
            "\tExtraTreesEntr_BAG_L2: \t{'criterion': 'entropy', 'max_depth': 15, 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass'], 'model_type': <class 'autogluon.tabular.models.xt.xt_model.XTModel'>, 'priority': 60}, 'ag_args_ensemble': {'use_child_oof': True, 'save_bag_folds': False}}\n",
            "\tNeuralNetFastAI_BAG_L2: \t{'ag_args': {'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>, 'priority': 50}, 'ag_args_ensemble': {'save_bag_folds': False}}\n",
            "\tXGBoost_BAG_L2: \t{'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'softclass'], 'model_type': <class 'autogluon.tabular.models.xgboost.xgboost_model.XGBoostModel'>, 'priority': 40}, 'ag_args_ensemble': {'save_bag_folds': False}}\n",
            "\tNeuralNetTorch_BAG_L2: \t{'ag_args': {'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>, 'priority': 25}, 'ag_args_ensemble': {'save_bag_folds': False}}\n",
            "\tLightGBMLarge_BAG_L2: \t{'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 5, 'ag_args': {'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>, 'name_suffix': 'Large', 'hyperparameter_tune_kwargs': None, 'priority': 0}, 'ag_args_ensemble': {'save_bag_folds': False}}\n",
            "Fitting 11 L2 models ...\n",
            "Loading: /content/AutoGluonModels/models/LightGBMXT_BAG_L1/utils/oof.pkl\n",
            "Loading: /content/AutoGluonModels/models/LightGBM_BAG_L1/utils/oof.pkl\n",
            "Loading: /content/AutoGluonModels/models/RandomForestGini_BAG_L1/utils/oof.pkl\n",
            "Loading: /content/AutoGluonModels/models/RandomForestEntr_BAG_L1/utils/oof.pkl\n",
            "Loading: /content/AutoGluonModels/models/CatBoost_BAG_L1/utils/oof.pkl\n",
            "Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 773.63s of the 772.81s of remaining time.\n",
            "\tFitting LightGBMXT_BAG_L2 with 'num_gpus': 0, 'num_cpus': 96\n",
            "Saving /content/AutoGluonModels/models/LightGBMXT_BAG_L2/utils/model_template.pkl\n",
            "Loading: /content/AutoGluonModels/models/LightGBMXT_BAG_L2/utils/model_template.pkl\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=12, gpus=0, memory=3.73%)\n",
            "Saving /content/AutoGluonModels/models/LightGBMXT_BAG_L2/utils/oof.pkl\n",
            "Saving /content/AutoGluonModels/models/LightGBMXT_BAG_L2/model.pkl\n",
            "\t0.9778\t = Validation score   (roc_auc)\n",
            "\t72.3s\t = Training   runtime\n",
            "\t5.95s\t = Validation runtime\n",
            "\t313.0\t = Inference  throughput (rows/s | 73818 batch size)\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Fitting model: LightGBM_BAG_L2 ... Training model for up to 692.37s of the 691.55s of remaining time.\n",
            "\tFitting LightGBM_BAG_L2 with 'num_gpus': 0, 'num_cpus': 96\n",
            "Saving /content/AutoGluonModels/models/LightGBM_BAG_L2/utils/model_template.pkl\n",
            "Loading: /content/AutoGluonModels/models/LightGBM_BAG_L2/utils/model_template.pkl\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=12, gpus=0, memory=3.73%)\n",
            "Saving /content/AutoGluonModels/models/LightGBM_BAG_L2/utils/oof.pkl\n",
            "Saving /content/AutoGluonModels/models/LightGBM_BAG_L2/model.pkl\n",
            "\t0.978\t = Validation score   (roc_auc)\n",
            "\t34.77s\t = Training   runtime\n",
            "\t3.15s\t = Validation runtime\n",
            "\t316.8\t = Inference  throughput (rows/s | 73818 batch size)\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Fitting model: RandomForestGini_BAG_L2 ... Training model for up to 648.95s of the 648.12s of remaining time.\n",
            "\tFitting RandomForestGini_BAG_L2 with 'num_gpus': 0, 'num_cpus': 96\n",
            "Saving /content/AutoGluonModels/models/RandomForestGini_BAG_L2/utils/model_template.pkl\n",
            "Loading: /content/AutoGluonModels/models/RandomForestGini_BAG_L2/utils/model_template.pkl\n",
            "\t168.28s\t= Estimated out-of-fold prediction time...\n",
            "\t`use_child_oof` was specified for this model. It will function similarly to a bagged model, but will only fit one child model.\n",
            "Saving /content/AutoGluonModels/models/RandomForestGini_BAG_L2/utils/oof.pkl\n",
            "Saving /content/AutoGluonModels/models/RandomForestGini_BAG_L2/model.pkl\n",
            "\t0.9652\t = Validation score   (roc_auc)\n",
            "\t34.21s\t = Training   runtime\n",
            "\t127.49s\t = Validation runtime\n",
            "\t300.3\t = Inference  throughput (rows/s | 73818 batch size)\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Fitting model: RandomForestEntr_BAG_L2 ... Training model for up to 483.71s of the 482.88s of remaining time.\n",
            "\tFitting RandomForestEntr_BAG_L2 with 'num_gpus': 0, 'num_cpus': 96\n",
            "Saving /content/AutoGluonModels/models/RandomForestEntr_BAG_L2/utils/model_template.pkl\n",
            "Loading: /content/AutoGluonModels/models/RandomForestEntr_BAG_L2/utils/model_template.pkl\n",
            "\t139.89s\t= Estimated out-of-fold prediction time...\n",
            "\t`use_child_oof` was specified for this model. It will function similarly to a bagged model, but will only fit one child model.\n",
            "Saving /content/AutoGluonModels/models/RandomForestEntr_BAG_L2/utils/oof.pkl\n",
            "Saving /content/AutoGluonModels/models/RandomForestEntr_BAG_L2/model.pkl\n",
            "\t0.9715\t = Validation score   (roc_auc)\n",
            "\t33.57s\t = Training   runtime\n",
            "\t128.5s\t = Validation runtime\n",
            "\t300.2\t = Inference  throughput (rows/s | 73818 batch size)\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Fitting model: CatBoost_BAG_L2 ... Training model for up to 318.13s of the 317.3s of remaining time.\n",
            "\tFitting CatBoost_BAG_L2 with 'num_gpus': 0, 'num_cpus': 96\n",
            "Saving /content/AutoGluonModels/models/CatBoost_BAG_L2/utils/model_template.pkl\n",
            "Loading: /content/AutoGluonModels/models/CatBoost_BAG_L2/utils/model_template.pkl\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=12, gpus=0, memory=3.76%)\n",
            "Saving /content/AutoGluonModels/models/CatBoost_BAG_L2/utils/oof.pkl\n",
            "Saving /content/AutoGluonModels/models/CatBoost_BAG_L2/model.pkl\n",
            "\t0.9772\t = Validation score   (roc_auc)\n",
            "\t255.15s\t = Training   runtime\n",
            "\t1.75s\t = Validation runtime\n",
            "\t318.7\t = Inference  throughput (rows/s | 73818 batch size)\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Fitting model: ExtraTreesGini_BAG_L2 ... Training model for up to 54.35s of the 53.52s of remaining time.\n",
            "\tFitting ExtraTreesGini_BAG_L2 with 'num_gpus': 0, 'num_cpus': 96\n",
            "Saving /content/AutoGluonModels/models/ExtraTreesGini_BAG_L2/utils/model_template.pkl\n",
            "Loading: /content/AutoGluonModels/models/ExtraTreesGini_BAG_L2/utils/model_template.pkl\n",
            "\t166.55s\t= Estimated out-of-fold prediction time...\n",
            "\tNot enough time to generate out-of-fold predictions for model. Estimated time required was 166.55s compared to 41.12s of available time.\n",
            "\tTime limit exceeded... Skipping ExtraTreesGini_BAG_L2.\n",
            "Loading: /content/AutoGluonModels/models/ExtraTreesGini_BAG_L2/utils/model_template.pkl\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Fitting model: ExtraTreesEntr_BAG_L2 ... Training model for up to 21.25s of the 20.42s of remaining time.\n",
            "\tFitting ExtraTreesEntr_BAG_L2 with 'num_gpus': 0, 'num_cpus': 96\n",
            "Saving /content/AutoGluonModels/models/ExtraTreesEntr_BAG_L2/utils/model_template.pkl\n",
            "Loading: /content/AutoGluonModels/models/ExtraTreesEntr_BAG_L2/utils/model_template.pkl\n",
            "\t168.31s\t= Estimated out-of-fold prediction time...\n",
            "\tNot enough time to generate out-of-fold predictions for model. Estimated time required was 168.31s compared to 10s of available time.\n",
            "\tTime limit exceeded... Skipping ExtraTreesEntr_BAG_L2.\n",
            "Loading: /content/AutoGluonModels/models/ExtraTreesEntr_BAG_L2/utils/model_template.pkl\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetFastAI_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Skipping XGBoost_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Skipping NeuralNetTorch_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Skipping LightGBMLarge_BAG_L2 due to lack of time remaining.\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Loading: /content/AutoGluonModels/models/LightGBMXT_BAG_L1/utils/oof.pkl\n",
            "Loading: /content/AutoGluonModels/models/LightGBM_BAG_L1/utils/oof.pkl\n",
            "Loading: /content/AutoGluonModels/models/RandomForestGini_BAG_L1/utils/oof.pkl\n",
            "Loading: /content/AutoGluonModels/models/RandomForestEntr_BAG_L1/utils/oof.pkl\n",
            "Loading: /content/AutoGluonModels/models/CatBoost_BAG_L1/utils/oof.pkl\n",
            "Loading: /content/AutoGluonModels/models/LightGBMXT_BAG_L2/utils/oof.pkl\n",
            "Loading: /content/AutoGluonModels/models/LightGBM_BAG_L2/utils/oof.pkl\n",
            "Loading: /content/AutoGluonModels/models/RandomForestGini_BAG_L2/utils/oof.pkl\n",
            "Loading: /content/AutoGluonModels/models/RandomForestEntr_BAG_L2/utils/oof.pkl\n",
            "Loading: /content/AutoGluonModels/models/CatBoost_BAG_L2/utils/oof.pkl\n",
            "Model configs that will be trained (in order):\n",
            "\tWeightedEnsemble_L3: \t{'ag_args': {'valid_base': False, 'name_bag_suffix': '', 'model_type': <class 'autogluon.core.models.greedy_ensemble.greedy_weighted_ensemble_model.GreedyWeightedEnsembleModel'>, 'priority': 0}, 'ag_args_ensemble': {'save_bag_folds': False}}\n",
            "Fitting model: WeightedEnsemble_L3 ... Training model for up to 360.0s of the -12.77s of remaining time.\n",
            "\tFitting WeightedEnsemble_L3 with 'num_gpus': 0, 'num_cpus': 96\n",
            "Saving /content/AutoGluonModels/models/WeightedEnsemble_L3/utils/model_template.pkl\n",
            "Loading: /content/AutoGluonModels/models/WeightedEnsemble_L3/utils/model_template.pkl\n",
            "Ensemble size: 25\n",
            "Ensemble weights: \n",
            "[0.   0.   0.   0.   0.   0.36 0.32 0.   0.04 0.28]\n",
            "\t2.02s\t= Estimated out-of-fold prediction time...\n",
            "Saving /content/AutoGluonModels/models/WeightedEnsemble_L3/utils/oof.pkl\n",
            "Saving /content/AutoGluonModels/models/WeightedEnsemble_L3/model.pkl\n",
            "\tEnsemble Weights: {'LightGBMXT_BAG_L2': 0.36, 'LightGBM_BAG_L2': 0.32, 'CatBoost_BAG_L2': 0.28, 'RandomForestEntr_BAG_L2': 0.04}\n",
            "\t0.9785\t = Validation score   (roc_auc)\n",
            "\t25.9s\t = Training   runtime\n",
            "\t0.1s\t = Validation runtime\n",
            "\t287.5\t = Inference  throughput (rows/s | 73818 batch size)\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "AutoGluon training complete, total runtime = 2446.5s ... Best model: WeightedEnsemble_L3 | Estimated inference throughput: 287.5 rows/s (73818 batch size)\n",
            "Loading: /content/AutoGluonModels/models/trainer.pkl\n",
            "Automatically performing refit_full as a post-fit operation (due to `.fit(..., refit_full=True)`\n",
            "Refitting models via `predictor.refit_full` using all of the data (combined train and validation)...\n",
            "\tModels trained in this way will have the suffix \"_FULL\" and have NaN validation score.\n",
            "\tThis process is not bound by time_limit, but should take less time than the original `predictor.fit` call.\n",
            "\tTo learn more, refer to the `.refit_full` method docstring which explains how \"_FULL\" models differ from normal models.\n",
            "Loading: /content/AutoGluonModels/utils/data/X.pkl\n",
            "Loading: /content/AutoGluonModels/utils/data/y.pkl\n",
            "Loading: /content/AutoGluonModels/models/LightGBMXT_BAG_L1/model.pkl\n",
            "Loading: /content/AutoGluonModels/models/LightGBMXT_BAG_L1/utils/model_template.pkl\n",
            "Loading: /content/AutoGluonModels/models/LightGBMXT_BAG_L1/utils/model_template.pkl\n",
            "Loading: /content/AutoGluonModels/models/LightGBMXT_BAG_L1/utils/model_template.pkl\n",
            "Fitting 1 L1 models ...\n",
            "Fitting model: LightGBMXT_BAG_L1_FULL ...\n",
            "\tFitting LightGBMXT_BAG_L1_FULL with 'num_gpus': 0, 'num_cpus': 48\n",
            "Saving /content/AutoGluonModels/models/LightGBMXT_BAG_L1_FULL/utils/model_template.pkl\n",
            "Loading: /content/AutoGluonModels/models/LightGBMXT_BAG_L1_FULL/utils/model_template.pkl\n",
            "\tFitting 8061 rounds... Hyperparameters: {'learning_rate': 0.05, 'extra_trees': True}\n",
            "Saving /content/AutoGluonModels/models/LightGBMXT_BAG_L1_FULL/model.pkl\n",
            "\t213.12s\t = Training   runtime\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Loading: /content/AutoGluonModels/models/LightGBM_BAG_L1/model.pkl\n",
            "Loading: /content/AutoGluonModels/models/LightGBM_BAG_L1/utils/model_template.pkl\n",
            "Loading: /content/AutoGluonModels/models/LightGBM_BAG_L1/utils/model_template.pkl\n",
            "Loading: /content/AutoGluonModels/models/LightGBM_BAG_L1/utils/model_template.pkl\n",
            "Fitting 1 L1 models ...\n",
            "Fitting model: LightGBM_BAG_L1_FULL ...\n",
            "\tFitting LightGBM_BAG_L1_FULL with 'num_gpus': 0, 'num_cpus': 48\n",
            "Saving /content/AutoGluonModels/models/LightGBM_BAG_L1_FULL/utils/model_template.pkl\n",
            "Loading: /content/AutoGluonModels/models/LightGBM_BAG_L1_FULL/utils/model_template.pkl\n",
            "\tFitting 5804 rounds... Hyperparameters: {'learning_rate': 0.05}\n",
            "Saving /content/AutoGluonModels/models/LightGBM_BAG_L1_FULL/model.pkl\n",
            "\t149.83s\t = Training   runtime\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Loading: /content/AutoGluonModels/models/RandomForestGini_BAG_L1/model.pkl\n",
            "Fitting model: RandomForestGini_BAG_L1_FULL | Skipping fit via cloning parent ...\n",
            "\t37.55s\t = Training   runtime\n",
            "\t125.71s\t = Validation runtime\n",
            "\t4697.6\t = Inference  throughput (rows/s | 590540 batch size)\n",
            "Saving /content/AutoGluonModels/models/RandomForestGini_BAG_L1_FULL/model.pkl\n",
            "Loading: /content/AutoGluonModels/models/RandomForestEntr_BAG_L1/model.pkl\n",
            "Fitting model: RandomForestEntr_BAG_L1_FULL | Skipping fit via cloning parent ...\n",
            "\t33.07s\t = Training   runtime\n",
            "\t127.03s\t = Validation runtime\n",
            "\t4648.7\t = Inference  throughput (rows/s | 590540 batch size)\n",
            "Saving /content/AutoGluonModels/models/RandomForestEntr_BAG_L1_FULL/model.pkl\n",
            "Loading: /content/AutoGluonModels/models/CatBoost_BAG_L1/model.pkl\n",
            "Loading: /content/AutoGluonModels/models/CatBoost_BAG_L1/utils/model_template.pkl\n",
            "Loading: /content/AutoGluonModels/models/CatBoost_BAG_L1/utils/model_template.pkl\n",
            "Loading: /content/AutoGluonModels/models/CatBoost_BAG_L1/utils/model_template.pkl\n",
            "Fitting 1 L1 models ...\n",
            "Fitting model: CatBoost_BAG_L1_FULL ...\n",
            "\tFitting CatBoost_BAG_L1_FULL with 'num_gpus': 0, 'num_cpus': 48\n",
            "Saving /content/AutoGluonModels/models/CatBoost_BAG_L1_FULL/utils/model_template.pkl\n",
            "Loading: /content/AutoGluonModels/models/CatBoost_BAG_L1_FULL/utils/model_template.pkl\n",
            "\tCatboost model hyperparameters: {'iterations': 7, 'learning_rate': 0.05, 'random_seed': 0, 'allow_writing_files': False, 'eval_metric': 'Logloss', 'thread_count': 48}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0:\tlearn: 0.6121004\ttotal: 167ms\tremaining: 1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Saving /content/AutoGluonModels/models/CatBoost_BAG_L1_FULL/model.pkl\n",
            "\t5.46s\t = Training   runtime\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Loading: /content/AutoGluonModels/models/LightGBMXT_BAG_L2/model.pkl\n",
            "Loading: /content/AutoGluonModels/models/LightGBMXT_BAG_L2/utils/model_template.pkl\n",
            "Loading: /content/AutoGluonModels/models/LightGBMXT_BAG_L2/utils/model_template.pkl\n",
            "Loading: /content/AutoGluonModels/models/LightGBMXT_BAG_L2/utils/model_template.pkl\n",
            "Fitting 1 L2 models ...\n",
            "Loading: /content/AutoGluonModels/models/LightGBMXT_BAG_L1/utils/oof.pkl\n",
            "Loading: /content/AutoGluonModels/models/LightGBM_BAG_L1/utils/oof.pkl\n",
            "Loading: /content/AutoGluonModels/models/RandomForestGini_BAG_L1/utils/oof.pkl\n",
            "Loading: /content/AutoGluonModels/models/RandomForestEntr_BAG_L1/utils/oof.pkl\n",
            "Loading: /content/AutoGluonModels/models/CatBoost_BAG_L1/utils/oof.pkl\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6:\tlearn: 0.3164583\ttotal: 753ms\tremaining: 0us\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Fitting model: LightGBMXT_BAG_L2_FULL ...\n",
            "\tFitting LightGBMXT_BAG_L2_FULL with 'num_gpus': 0, 'num_cpus': 48\n",
            "Saving /content/AutoGluonModels/models/LightGBMXT_BAG_L2_FULL/utils/model_template.pkl\n",
            "Loading: /content/AutoGluonModels/models/LightGBMXT_BAG_L2_FULL/utils/model_template.pkl\n",
            "\tFitting 500 rounds... Hyperparameters: {'learning_rate': 0.05, 'extra_trees': True}\n",
            "Saving /content/AutoGluonModels/models/LightGBMXT_BAG_L2_FULL/model.pkl\n",
            "\t24.33s\t = Training   runtime\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Loading: /content/AutoGluonModels/models/LightGBM_BAG_L2/model.pkl\n",
            "Loading: /content/AutoGluonModels/models/LightGBM_BAG_L2/utils/model_template.pkl\n",
            "Loading: /content/AutoGluonModels/models/LightGBM_BAG_L2/utils/model_template.pkl\n",
            "Loading: /content/AutoGluonModels/models/LightGBM_BAG_L2/utils/model_template.pkl\n",
            "Fitting 1 L2 models ...\n",
            "Loading: /content/AutoGluonModels/models/LightGBMXT_BAG_L1/utils/oof.pkl\n",
            "Loading: /content/AutoGluonModels/models/LightGBM_BAG_L1/utils/oof.pkl\n",
            "Loading: /content/AutoGluonModels/models/RandomForestGini_BAG_L1/utils/oof.pkl\n",
            "Loading: /content/AutoGluonModels/models/RandomForestEntr_BAG_L1/utils/oof.pkl\n",
            "Loading: /content/AutoGluonModels/models/CatBoost_BAG_L1/utils/oof.pkl\n",
            "Fitting model: LightGBM_BAG_L2_FULL ...\n",
            "\tFitting LightGBM_BAG_L2_FULL with 'num_gpus': 0, 'num_cpus': 48\n",
            "Saving /content/AutoGluonModels/models/LightGBM_BAG_L2_FULL/utils/model_template.pkl\n",
            "Loading: /content/AutoGluonModels/models/LightGBM_BAG_L2_FULL/utils/model_template.pkl\n",
            "\tFitting 161 rounds... Hyperparameters: {'learning_rate': 0.05}\n",
            "Saving /content/AutoGluonModels/models/LightGBM_BAG_L2_FULL/model.pkl\n",
            "\t14.19s\t = Training   runtime\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Loading: /content/AutoGluonModels/models/RandomForestEntr_BAG_L2/model.pkl\n",
            "Fitting model: RandomForestEntr_BAG_L2_FULL | Skipping fit via cloning parent ...\n",
            "\t33.57s\t = Training   runtime\n",
            "\t128.5s\t = Validation runtime\n",
            "\t300.2\t = Inference  throughput (rows/s | 73818 batch size)\n",
            "Saving /content/AutoGluonModels/models/RandomForestEntr_BAG_L2_FULL/model.pkl\n",
            "Loading: /content/AutoGluonModels/models/CatBoost_BAG_L2/model.pkl\n",
            "Loading: /content/AutoGluonModels/models/CatBoost_BAG_L2/utils/model_template.pkl\n",
            "Loading: /content/AutoGluonModels/models/CatBoost_BAG_L2/utils/model_template.pkl\n",
            "Loading: /content/AutoGluonModels/models/CatBoost_BAG_L2/utils/model_template.pkl\n",
            "Fitting 1 L2 models ...\n",
            "Loading: /content/AutoGluonModels/models/LightGBMXT_BAG_L1/utils/oof.pkl\n",
            "Loading: /content/AutoGluonModels/models/LightGBM_BAG_L1/utils/oof.pkl\n",
            "Loading: /content/AutoGluonModels/models/RandomForestGini_BAG_L1/utils/oof.pkl\n",
            "Loading: /content/AutoGluonModels/models/RandomForestEntr_BAG_L1/utils/oof.pkl\n",
            "Loading: /content/AutoGluonModels/models/CatBoost_BAG_L1/utils/oof.pkl\n",
            "Fitting model: CatBoost_BAG_L2_FULL ...\n",
            "\tFitting CatBoost_BAG_L2_FULL with 'num_gpus': 0, 'num_cpus': 48\n",
            "Saving /content/AutoGluonModels/models/CatBoost_BAG_L2_FULL/utils/model_template.pkl\n",
            "Loading: /content/AutoGluonModels/models/CatBoost_BAG_L2_FULL/utils/model_template.pkl\n",
            "\tCatboost model hyperparameters: {'iterations': 218, 'learning_rate': 0.05, 'random_seed': 0, 'allow_writing_files': False, 'eval_metric': 'Logloss', 'thread_count': 48}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0:\tlearn: 0.5719813\ttotal: 258ms\tremaining: 55.9s\n",
            "20:\tlearn: 0.0575983\ttotal: 4.94s\tremaining: 46.4s\n",
            "40:\tlearn: 0.0397486\ttotal: 9.43s\tremaining: 40.7s\n",
            "60:\tlearn: 0.0374595\ttotal: 14.1s\tremaining: 36.4s\n",
            "80:\tlearn: 0.0368754\ttotal: 18.8s\tremaining: 31.9s\n",
            "100:\tlearn: 0.0366908\ttotal: 23.5s\tremaining: 27.2s\n",
            "120:\tlearn: 0.0365256\ttotal: 27.9s\tremaining: 22.4s\n",
            "140:\tlearn: 0.0363970\ttotal: 32.6s\tremaining: 17.8s\n",
            "160:\tlearn: 0.0363196\ttotal: 37s\tremaining: 13.1s\n",
            "180:\tlearn: 0.0362517\ttotal: 41.4s\tremaining: 8.46s\n",
            "200:\tlearn: 0.0361939\ttotal: 45.8s\tremaining: 3.87s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Saving /content/AutoGluonModels/models/CatBoost_BAG_L2_FULL/model.pkl\n",
            "\t54.3s\t = Training   runtime\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Loading: /content/AutoGluonModels/models/WeightedEnsemble_L3/model.pkl\n",
            "Fitting model: WeightedEnsemble_L3_FULL | Skipping fit via cloning parent ...\n",
            "\tEnsemble Weights: {'LightGBMXT_BAG_L2': 0.36, 'LightGBM_BAG_L2': 0.32, 'CatBoost_BAG_L2': 0.28, 'RandomForestEntr_BAG_L2': 0.04}\n",
            "\t25.9s\t = Training   runtime\n",
            "Saving /content/AutoGluonModels/models/WeightedEnsemble_L3_FULL/model.pkl\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "217:\tlearn: 0.0361477\ttotal: 49.7s\tremaining: 0us\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loading: /content/AutoGluonModels/models/LightGBMXT_BAG_L1_FULL/model.pkl\n",
            "Saving /content/AutoGluonModels/models/LightGBMXT_BAG_L1_FULL/model.pkl\n",
            "Loading: /content/AutoGluonModels/models/LightGBM_BAG_L1_FULL/model.pkl\n",
            "Saving /content/AutoGluonModels/models/LightGBM_BAG_L1_FULL/model.pkl\n",
            "Loading: /content/AutoGluonModels/models/RandomForestGini_BAG_L1_FULL/model.pkl\n",
            "Saving /content/AutoGluonModels/models/RandomForestGini_BAG_L1_FULL/model.pkl\n",
            "Loading: /content/AutoGluonModels/models/RandomForestEntr_BAG_L1_FULL/model.pkl\n",
            "Saving /content/AutoGluonModels/models/RandomForestEntr_BAG_L1_FULL/model.pkl\n",
            "Loading: /content/AutoGluonModels/models/CatBoost_BAG_L1_FULL/model.pkl\n",
            "Saving /content/AutoGluonModels/models/CatBoost_BAG_L1_FULL/model.pkl\n",
            "Loading: /content/AutoGluonModels/models/LightGBMXT_BAG_L2_FULL/model.pkl\n",
            "Saving /content/AutoGluonModels/models/LightGBMXT_BAG_L2_FULL/model.pkl\n",
            "Loading: /content/AutoGluonModels/models/LightGBM_BAG_L2_FULL/model.pkl\n",
            "Saving /content/AutoGluonModels/models/LightGBM_BAG_L2_FULL/model.pkl\n",
            "Loading: /content/AutoGluonModels/models/RandomForestEntr_BAG_L2_FULL/model.pkl\n",
            "Saving /content/AutoGluonModels/models/RandomForestEntr_BAG_L2_FULL/model.pkl\n",
            "Loading: /content/AutoGluonModels/models/CatBoost_BAG_L2_FULL/model.pkl\n",
            "Saving /content/AutoGluonModels/models/CatBoost_BAG_L2_FULL/model.pkl\n",
            "Loading: /content/AutoGluonModels/models/WeightedEnsemble_L3_FULL/model.pkl\n",
            "Saving /content/AutoGluonModels/models/WeightedEnsemble_L3_FULL/model.pkl\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Updated best model to \"WeightedEnsemble_L3_FULL\" (Previously \"WeightedEnsemble_L3\"). AutoGluon will default to using \"WeightedEnsemble_L3_FULL\" for predict() and predict_proba().\n",
            "Refit complete, total runtime = 484.34s ... Best model: \"WeightedEnsemble_L3_FULL\"\n",
            "Loading: /content/AutoGluonModels/models/LightGBMXT_BAG_L1/model.pkl\n",
            "Deleting model LightGBMXT_BAG_L1. All files under /content/AutoGluonModels/models/LightGBMXT_BAG_L1 will be removed.\n",
            "Loading: /content/AutoGluonModels/models/LightGBM_BAG_L1/model.pkl\n",
            "Deleting model LightGBM_BAG_L1. All files under /content/AutoGluonModels/models/LightGBM_BAG_L1 will be removed.\n",
            "Loading: /content/AutoGluonModels/models/RandomForestGini_BAG_L1/model.pkl\n",
            "Deleting model RandomForestGini_BAG_L1. All files under /content/AutoGluonModels/models/RandomForestGini_BAG_L1 will be removed.\n",
            "Loading: /content/AutoGluonModels/models/RandomForestEntr_BAG_L1/model.pkl\n",
            "Deleting model RandomForestEntr_BAG_L1. All files under /content/AutoGluonModels/models/RandomForestEntr_BAG_L1 will be removed.\n",
            "Loading: /content/AutoGluonModels/models/CatBoost_BAG_L1/model.pkl\n",
            "Deleting model CatBoost_BAG_L1. All files under /content/AutoGluonModels/models/CatBoost_BAG_L1 will be removed.\n",
            "Loading: /content/AutoGluonModels/models/WeightedEnsemble_L2/model.pkl\n",
            "Deleting model WeightedEnsemble_L2. All files under /content/AutoGluonModels/models/WeightedEnsemble_L2 will be removed.\n",
            "Loading: /content/AutoGluonModels/models/LightGBMXT_BAG_L2/model.pkl\n",
            "Deleting model LightGBMXT_BAG_L2. All files under /content/AutoGluonModels/models/LightGBMXT_BAG_L2 will be removed.\n",
            "Loading: /content/AutoGluonModels/models/LightGBM_BAG_L2/model.pkl\n",
            "Deleting model LightGBM_BAG_L2. All files under /content/AutoGluonModels/models/LightGBM_BAG_L2 will be removed.\n",
            "Loading: /content/AutoGluonModels/models/RandomForestGini_BAG_L2/model.pkl\n",
            "Deleting model RandomForestGini_BAG_L2. All files under /content/AutoGluonModels/models/RandomForestGini_BAG_L2 will be removed.\n",
            "Loading: /content/AutoGluonModels/models/RandomForestEntr_BAG_L2/model.pkl\n",
            "Deleting model RandomForestEntr_BAG_L2. All files under /content/AutoGluonModels/models/RandomForestEntr_BAG_L2 will be removed.\n",
            "Loading: /content/AutoGluonModels/models/CatBoost_BAG_L2/model.pkl\n",
            "Deleting model CatBoost_BAG_L2. All files under /content/AutoGluonModels/models/CatBoost_BAG_L2 will be removed.\n",
            "Loading: /content/AutoGluonModels/models/WeightedEnsemble_L3/model.pkl\n",
            "Deleting model WeightedEnsemble_L3. All files under /content/AutoGluonModels/models/WeightedEnsemble_L3 will be removed.\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Saving /content/AutoGluonModels/models/trainer.pkl\n",
            "Saving /content/AutoGluonModels/learner.pkl\n",
            "Saving /content/AutoGluonModels/predictor.pkl\n",
            "Saving /content/AutoGluonModels/version.txt with contents \"1.1.1\"\n",
            "Saving /content/AutoGluonModels/metadata.json\n",
            "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/content/AutoGluonModels/\")\n",
            "Loading: /content/AutoGluonModels/models/LightGBMXT_BAG_L1_FULL/model.pkl\n",
            "Loading: /content/AutoGluonModels/models/LightGBM_BAG_L1_FULL/model.pkl\n",
            "Loading: /content/AutoGluonModels/models/RandomForestGini_BAG_L1_FULL/model.pkl\n",
            "Loading: /content/AutoGluonModels/models/RandomForestEntr_BAG_L1_FULL/model.pkl\n",
            "Loading: /content/AutoGluonModels/models/CatBoost_BAG_L1_FULL/model.pkl\n",
            "Loading: /content/AutoGluonModels/models/LightGBMXT_BAG_L2_FULL/model.pkl\n",
            "Loading: /content/AutoGluonModels/models/LightGBM_BAG_L2_FULL/model.pkl\n",
            "Loading: /content/AutoGluonModels/models/RandomForestEntr_BAG_L2_FULL/model.pkl\n",
            "Loading: /content/AutoGluonModels/models/CatBoost_BAG_L2_FULL/model.pkl\n",
            "Loading: /content/AutoGluonModels/models/WeightedEnsemble_L3_FULL/model.pkl\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "*** Summary of fit() ***\n",
            "Estimated performance of each model:\n",
            "                          model score_val eval_metric  pred_time_val    fit_time  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
            "0  RandomForestGini_BAG_L1_FULL      None     roc_auc     125.710804   37.550590              125.710804          37.550590            1       True          3\n",
            "1  RandomForestEntr_BAG_L1_FULL      None     roc_auc     127.032806   33.069827              127.032806          33.069827            1       True          4\n",
            "2      WeightedEnsemble_L3_FULL      None     roc_auc            NaN  591.306964                     NaN          25.897851            3       True         10\n",
            "3  RandomForestEntr_BAG_L2_FULL      None     roc_auc            NaN  472.592563              128.499431          33.567673            2       True          8\n",
            "4          LightGBM_BAG_L2_FULL      None     roc_auc            NaN  453.212598                     NaN          14.187708            2       True          7\n",
            "5          LightGBM_BAG_L1_FULL      None     roc_auc            NaN  149.826292                     NaN         149.826292            1       True          2\n",
            "6        LightGBMXT_BAG_L2_FULL      None     roc_auc            NaN  463.358219                     NaN          24.333328            2       True          6\n",
            "7        LightGBMXT_BAG_L1_FULL      None     roc_auc            NaN  213.119514                     NaN         213.119514            1       True          1\n",
            "8          CatBoost_BAG_L2_FULL      None     roc_auc            NaN  493.320404                     NaN          54.295514            2       True          9\n",
            "9          CatBoost_BAG_L1_FULL      None     roc_auc            NaN    5.458666                     NaN           5.458666            1       True          5\n",
            "Number of models trained: 10\n",
            "Types of models trained:\n",
            "{'WeightedEnsembleModel', 'StackerEnsembleModel_LGB', 'StackerEnsembleModel_CatBoost', 'StackerEnsembleModel_RF'}\n",
            "Bagging used: True  (with 8 folds)\n",
            "Multi-layer stack-ensembling used: True  (with 3 levels)\n",
            "Feature Metadata (Processed):\n",
            "(raw dtype, special dtypes):\n",
            "('category', []) :  31 | ['ProductCD', 'card4', 'card6', 'P_emaildomain', 'R_emaildomain', ...]\n",
            "('float', [])    : 394 | ['TransactionAmt', 'card2', 'card3', 'card5', 'addr1', ...]\n",
            "('int', [])      :   3 | ['TransactionID', 'TransactionDT', 'card1']\n",
            "*** End of fit() summary ***\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/autogluon/core/utils/plots.py:169: UserWarning: AutoGluon summary plots cannot be created because bokeh is not installed. To see plots, please do: \"pip install bokeh==2.0.1\"\n",
            "  warnings.warn('AutoGluon summary plots cannot be created because bokeh is not installed. To see plots, please do: \"pip install bokeh==2.0.1\"')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Display the column names of the training data\n",
        "print(\"Training Data Columns:\")\n",
        "print(train_data.columns)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "80ibL68IHO_V",
        "outputId": "b4cb1af0-cdbd-482e-df5e-af1ba8f7e3ed"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Data Columns:\n",
            "Index(['TransactionID', 'isFraud', 'TransactionDT', 'TransactionAmt',\n",
            "       'ProductCD', 'card1', 'card2', 'card3', 'card4', 'card5',\n",
            "       ...\n",
            "       'id_31', 'id_32', 'id_33', 'id_34', 'id_35', 'id_36', 'id_37', 'id_38',\n",
            "       'DeviceType', 'DeviceInfo'],\n",
            "      dtype='object', length=434)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Replace hyphens with underscores in train_identity column names to match train_transaction\n",
        "train_identity.columns = train_identity.columns.str.replace('-', '_')\n",
        "\n"
      ],
      "metadata": {
        "id": "E-FLR1G0IDPp"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Merge the training datasets on 'TransactionID'\n",
        "train_data = pd.merge(train_transaction, train_identity, on='TransactionID', how='left')\n"
      ],
      "metadata": {
        "id": "VYn-m5f6uiZP"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display the first few rows of the training data\n",
        "print(\"First few rows of the training data:\")\n",
        "print(train_data.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oa-Drgy8DypR",
        "outputId": "82cb17ec-803f-4f1e-fa15-1f86b50ca661"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First few rows of the training data:\n",
            "   TransactionID  isFraud  TransactionDT  TransactionAmt ProductCD  card1  \\\n",
            "0        2987000        0          86400            68.5         W  13926   \n",
            "1        2987001        0          86401            29.0         W   2755   \n",
            "2        2987002        0          86469            59.0         W   4663   \n",
            "3        2987003        0          86499            50.0         W  18132   \n",
            "4        2987004        0          86506            50.0         H   4497   \n",
            "\n",
            "   card2  card3       card4  card5  ...                id_31  id_32  \\\n",
            "0    NaN  150.0    discover  142.0  ...                  NaN    NaN   \n",
            "1  404.0  150.0  mastercard  102.0  ...                  NaN    NaN   \n",
            "2  490.0  150.0        visa  166.0  ...                  NaN    NaN   \n",
            "3  567.0  150.0  mastercard  117.0  ...                  NaN    NaN   \n",
            "4  514.0  150.0  mastercard  102.0  ...  samsung browser 6.2   32.0   \n",
            "\n",
            "       id_33           id_34  id_35 id_36 id_37  id_38  DeviceType  \\\n",
            "0        NaN             NaN    NaN   NaN   NaN    NaN         NaN   \n",
            "1        NaN             NaN    NaN   NaN   NaN    NaN         NaN   \n",
            "2        NaN             NaN    NaN   NaN   NaN    NaN         NaN   \n",
            "3        NaN             NaN    NaN   NaN   NaN    NaN         NaN   \n",
            "4  2220x1080  match_status:2      T     F     T      T      mobile   \n",
            "\n",
            "                      DeviceInfo  \n",
            "0                            NaN  \n",
            "1                            NaN  \n",
            "2                            NaN  \n",
            "3                            NaN  \n",
            "4  SAMSUNG SM-G892A Build/NRD90M  \n",
            "\n",
            "[5 rows x 434 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions on the test data\n",
        "# Note: Since 'isFraud' is not in test_data, ensure it is removed from the features if present\n",
        "if 'isFraud' in train_data.columns:\n",
        "    test_data = train_data.drop(columns=['isFraud'])"
      ],
      "metadata": {
        "id": "iu0Jr9g6D_NX"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict the probability of the positive class (fraudulent transactions)\n",
        "y_pred_proba = predictor.predict_proba(test_data, as_multiclass=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SgUwIjfHEOfH",
        "outputId": "87669a40-89e9-4276-f324-223afddecb90"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loading: /content/AutoGluonModels/models/CatBoost_BAG_L1_FULL/model.pkl\n",
            "Loading: /content/AutoGluonModels/models/LightGBMXT_BAG_L1_FULL/model.pkl\n",
            "Loading: /content/AutoGluonModels/models/LightGBM_BAG_L1_FULL/model.pkl\n",
            "Loading: /content/AutoGluonModels/models/RandomForestEntr_BAG_L1_FULL/model.pkl\n",
            "Loading: /content/AutoGluonModels/models/RandomForestGini_BAG_L1_FULL/model.pkl\n",
            "Loading: /content/AutoGluonModels/models/CatBoost_BAG_L2_FULL/model.pkl\n",
            "Loading: /content/AutoGluonModels/models/LightGBMXT_BAG_L2_FULL/model.pkl\n",
            "Loading: /content/AutoGluonModels/models/LightGBM_BAG_L2_FULL/model.pkl\n",
            "Loading: /content/AutoGluonModels/models/RandomForestEntr_BAG_L2_FULL/model.pkl\n",
            "Loading: /content/AutoGluonModels/models/WeightedEnsemble_L3_FULL/model.pkl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the sample submission file\n",
        "submission = pd.read_csv(directory + 'sample_submission.csv')"
      ],
      "metadata": {
        "id": "ztCttQFmEWcX"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display the first few rows of the submission file\n",
        "print(\"First few rows of the submission file:\")\n",
        "print(submission.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OAe6muehEnoS",
        "outputId": "c50b640d-13a1-4ea9-d3ca-5c81cbd4e28b"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First few rows of the submission file:\n",
            "   TransactionID  isFraud\n",
            "0        3663549      0.5\n",
            "1        3663550      0.5\n",
            "2        3663551      0.5\n",
            "3        3663552      0.5\n",
            "4        3663553      0.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the submission file\n",
        "submission.to_csv(directory + 'my_submission.csv', index=False)\n",
        "\n",
        "print(\"\\nSubmission file saved to:\", directory + 'my_submission.csv')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "11CH1GDyEp_O",
        "outputId": "a9bffcf3-4207-4d1d-808b-8a48c4c2aab7"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Submission file saved to: /content/my_submission.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ug46sJO8E0-w"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}